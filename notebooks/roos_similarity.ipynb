{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('histaware-RplM6c3o-py3.8': venv)",
   "display_name": "Python 3.8.5 64-bit ('histaware-RplM6c3o-py3.8': venv)",
   "metadata": {
    "interpreter": {
     "hash": "86315069d9bbcc5e7b6a2d7416b15171a30b5af37cfb10a9c473db24ce95b203"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from string import punctuation\n",
    "sys.path.append(\"/Users/leonardovida/dev/HistAware\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.sentiment import vader\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from src import iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieved saved files\n",
    "csv = iterators.iterate_directory(\"../data/processed/selected_articles/\", \".csv\")\n",
    "df = pd.concat([pd.read_csv(c[\"article_path\"]) for c in csv],ignore_index=True)\n",
    "df.sort_values(by=[\"count\"], ascending=False, inplace=True)"
   ]
  },
  {
   "source": [
    "You are interested in `df[\"text\"]` (or df.text). Which is the column that contains all the selected texts.\n",
    "\n",
    "What we would like to do is to select similar texts based on a golden sample of texts. \n",
    "- Which means that we will go through all our dataset and select based on the frequency of the appearance of certain words (oil, gas and coal)\n",
    "- After that the results are ranked based on the number of matches of these words and these synonyms.\n",
    "- Once that is done, you have the `df` at hand in this notebook.\n",
    "\n",
    "You can assume that the first 100 rows of this dataframe are the \"golden\" labelled text representing texts we want to find similar texts to."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[0:100]\n",
    "df_remaining = df[101:]"
   ]
  },
  {
   "source": [
    "I suggest you to look at the examples every time you want to \"understand the score\" instead of looking only at the similarity score you will get. If you have time you could go through the first 100 rows and create a even better selection.... :)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### A small start"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=5744.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40ce0fdfff5d43ef95e771fb6dbc04b8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's create a list of text, just to experiment with the text\n",
    "word_nl=[]\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    word_nl.append(row[\"text\"])"
   ]
  },
  {
   "source": [
    "Cleaning the list of words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_nl=[\"\".join([l for l in word if l not in punctuation]) for word in word_nl]  #remove punctuation\n",
    "word_nl=[word.lower() for word in word_nl]  # convert to lower case\n",
    "word_nl=[\" \".join(word.split()) for word in word_nl]   # remove double spaces by splitting the strings into words and joining these words again\n",
    "word_nl=[re.sub(r'[^a-zA-z\\s]', '', word) for word in word_nl]  # to remove special characters and symbols"
   ]
  },
  {
   "source": [
    "These are not always necessary! We are losing \"meaning\". However, on the types of analyses you will do these steps might be useful. Try with and without!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "From here apply the tf-idf/BM 25 or other similarity algorithms!\n",
    "- Use the documentation (and internent examples) from the following libraries:\n",
    "    - nltk --> for the already-written-out main algorithms. This will be your main library with:\n",
    "    - gensim\n",
    "    - Enchant (might be useful)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}