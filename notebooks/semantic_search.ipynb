{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('histaware-RplM6c3o-py3.8': venv)",
   "display_name": "Python 3.8.5 64-bit ('histaware-RplM6c3o-py3.8': venv)",
   "metadata": {
    "interpreter": {
     "hash": "86315069d9bbcc5e7b6a2d7416b15171a30b5af37cfb10a9c473db24ce95b203"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/leonardovida/dev/HistAware\")\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, util\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from src import iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "source": [
    "# Sentence Transformer "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the model - Bertje\n",
    "tokenizer = BertTokenizer.from_pretrained(\"wietsedv/bert-base-dutch-cased\")\n",
    "model = BertModel.from_pretrained(\"wietsedv/bert-base-dutch-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;../data/processed/selected_articles//2020-10-12_aardgas.csv&#39;,\n &#39;../data/processed/selected_articles//2020-10-12_olie.csv&#39;,\n &#39;../data/processed/selected_articles//2020-10-12_steenkool.csv&#39;]"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# Setup the file\n",
    "csv = iterators.iterate_directory(\"../data/processed/selected_articles/\", \".csv\")\n",
    "[c[\"article_path\"] for c in csv]\n",
    "\n",
    "#df = pd.read_csv(\"../data/processed/selected_articles/2020-10-07_aardgas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[0:100]\n",
    "df_remaining = df[101:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "572\n789\n1215\n840\n967\n4711\n767\n1433\n896\n1379\n1955\n1012\n6743\n1609\n761\n1193\n1599\n1340\n1506\n993\n956\n4046\n2227\n714\n765\n768\n3719\n1148\n1489\n953\n1287\n855\n666\n817\n2554\n1449\n3613\n1782\n1783\n13245\n762\n1825\n723\n2436\n768\n546\n895\n1049\n1139\n749\n6569\n2476\n660\n1868\n3942\n1617\n821\n1288\n3864\n747\n2615\n2462\n841\n2189\n890\n1093\n1408\n2505\n5951\n530\n825\n1594\n1777\n1830\n9891\n2598\n2148\n2741\n3517\n1243\n2244\n1174\n938\n847\n595\n3414\n1812\n525\n1494\n2082\n2574\n860\n2012\n2463\n1069\n1045\n681\n803\n1867\n1414\n1082\n2394\n876\n2308\n1850\n7834\n1643\n1205\n640\n1337\n1433\n591\n2664\n1658\n642\n557\n730\n585\n5513\n6297\n1086\n1339\n5698\n2687\n1578\n1238\n1022\n837\n1845\n587\n1658\n2368\n7126\n1094\n2564\n3955\n2118\n968\n1055\n2148\n1133\n1179\n972\n1831\n3455\n1431\n5784\n1486\n633\n961\n1048\n600\n652\n2595\n919\n3122\n1815\n1589\n1360\n1009\n1087\n2408\n3109\n799\n1175\n696\n1602\n787\n2272\n4479\n1193\n1588\n2003\n678\n2037\n1103\n1029\n2341\n1374\n547\n2009\n2244\n1404\n1540\n1753\n1835\n748\n699\n523\n2085\n891\n3628\n2386\n544\n2848\n549\n1174\n1845\n4220\n2774\n1036\n598\n826\n1156\n647\n971\n2557\n1727\n948\n818\n2445\n3455\n1465\n2164\n6763\n1969\n2053\n2951\n1554\n1182\n630\n1292\n893\n1578\n1109\n3133\n629\n3018\n2421\n599\n1925\n542\n668\n1548\n1106\n1493\n814\n621\n628\n863\n974\n937\n2742\n2914\n1530\n2253\n511\n596\n1597\n2806\n4081\n3198\n1967\n958\n836\n3605\n3424\n913\n865\n1613\n1564\n6346\n1649\n3392\n2977\n2673\n552\n2986\n550\n636\n1302\n1155\n792\n1782\n5038\n605\n901\n2033\n1083\n2055\n1124\n1463\n3090\n3128\n956\n3986\n1353\n624\n1062\n1565\n1039\n1800\n564\n3015\n3504\n1368\n878\n943\n5870\n3130\n5681\n628\n1551\n1591\n1988\n1852\n9169\n1761\n1436\n2830\n2929\n3278\n1475\n1117\n5163\n560\n1241\n1419\n763\n865\n1211\n1065\n1425\n2068\n1015\n1311\n852\n2282\n1333\n1285\n1780\n1286\n682\n765\n1506\n850\n894\n536\n1188\n947\n3267\n2169\n1111\n684\n662\n766\n876\n2158\n613\n2471\n5173\n733\n862\n2812\n1189\n1885\n1892\n2090\n1387\n641\n1565\n2381\n1269\n2061\n1982\n741\n1732\n1117\n982\n1088\n4008\n3661\n2960\n1647\n1212\n2860\n664\n629\n1663\n977\n2730\n1036\n2324\n848\n2994\n895\n1609\n2517\n5698\n921\n5154\n1391\n6987\n635\n4493\n2091\n772\n1835\n2014\n1103\n1084\n1375\n989\n1617\n2070\n13795\n7649\n1399\n1384\n1196\n538\n2190\n739\n2855\n3064\n6576\n522\n2752\n1266\n940\n683\n1240\n1785\n649\n859\n1831\n5739\n1472\n2365\n1568\n2646\n708\n2048\n1340\n5746\n1954\n1984\n828\n1872\n593\n673\n652\n1816\n734\n693\n1917\n1896\n1545\n1689\n927\n2096\n1550\n5115\n2993\n665\n5973\n878\n786\n611\n921\n1142\n3801\n708\n822\n1244\n954\n1054\n2604\n1150\n638\n4517\n2136\n1387\n1848\n1979\n3141\n2136\n1507\n2453\n2059\n1801\n1883\n1432\n1016\n2543\n993\n2839\n804\n1062\n2990\n652\n811\n1658\n1892\n1397\n584\n3069\n746\n1315\n5245\n758\n1949\n826\n1189\n3535\n1751\n4045\n701\n745\n2085\n2657\n3285\n2537\n2055\n2979\n1220\n1454\n4082\n2018\n1035\n697\n1454\n3160\n3313\n1371\n606\n1039\n1824\n4405\n1155\n1196\n1033\n812\n1118\n1783\n2035\n563\n3129\n2260\n1669\n2804\n806\n2852\n917\n4225\n1097\n2286\n3713\n1060\n6588\n2744\n1341\n1000\n1492\n1047\n641\n2450\n858\n1171\n9732\n852\n2119\n1295\n1311\n2380\n1033\n3270\n3528\n2551\n3219\n2850\n922\n1753\n1861\n919\n1905\n3634\n1836\n2201\n3225\n2078\n1605\n1893\n1454\n1909\n2403\n1260\n586\n1805\n545\n2071\n6286\n2553\n1325\n2083\n1374\n1816\n3703\n2377\n8945\n1408\n1036\n2143\n626\n1029\n799\n2080\n1677\n683\n1377\n558\n3262\n1061\n1203\n737\n514\n1579\n1038\n1770\n2177\n1411\n994\n1829\n739\n1567\n1118\n2334\n604\n4939\n2308\n949\n633\n1992\n1692\n1072\n1006\n1396\n2236\n728\n830\n1939\n763\n961\n1278\n736\n524\n2948\n743\n792\n1221\n1768\n1100\n2081\n1227\n902\n1052\n1708\n822\n2645\n1089\n2693\n1463\n608\n975\n2086\n2418\n1430\n1894\n1307\n1292\n2470\n2418\n1949\n1059\n1973\n3527\n952\n1446\n593\n2481\n852\n857\n1079\n1625\n1258\n1012\n1158\n1204\n817\n1310\n757\n764\n1020\n1757\n1719\n628\n2765\n2194\n1238\n1299\n681\n2108\n3496\n1020\n1199\n1780\n8521\n1538\n1392\n1012\n1502\n2395\n1833\n2436\n1767\n2190\n869\n1759\n954\n1392\n1139\n1552\n1704\n889\n1316\n591\n1271\n1741\n957\n523\n1263\n7222\n1612\n2165\n888\n1418\n3780\n3942\n1903\n894\n659\n540\n1270\n1061\n1492\n1714\n6305\n3509\n754\n3536\n1709\n1735\n814\n877\n691\n890\n1109\n1107\n836\n613\n565\n1234\n1790\n930\n776\n1071\n1460\n2661\n5063\n5229\n2534\n1659\n2855\n891\n5255\n6383\n1132\n2601\n1113\n1182\n1551\n820\n1252\n2968\n8241\n1028\n794\n1026\n1774\n1990\n1322\n698\n519\n585\n1143\n2533\n631\n949\n3775\n6632\n669\n1313\n2024\n761\n2892\n1814\n5769\n4054\n585\n2936\n1206\n1308\n644\n1888\n905\n642\n925\n2054\n1056\n813\n693\n629\n1244\n889\n744\n512\n799\n977\n1116\n1022\n2039\n1551\n1906\n1504\n2570\n860\n1229\n2359\n1890\n1616\n518\n4912\n4865\n1678\n2813\n690\n926\n2819\n1413\n1752\n1155\n571\n2042\n2191\n3933\n668\n645\n537\n1137\n2039\n1058\n562\n2434\n516\n5930\n2758\n1122\n761\n3237\n528\n2323\n977\n6697\n3017\n932\n2664\n647\n517\n2941\n2940\n1901\n874\n698\n592\n683\n1302\n1094\n1894\n2257\n723\n1022\n2021\n2192\n1860\n1271\n1699\n1147\n2270\n997\n1212\n593\n1758\n8865\n738\n1382\n1616\n1962\n1082\n1046\n1049\n2140\n1179\n674\n3288\n706\n1097\n1728\n1455\n3139\n1901\n3464\n2096\n2653\n2672\n2115\n908\n661\n1807\n514\n1512\n3486\n1952\n769\n1086\n1176\n936\n2141\n2153\n2777\n1534\n2327\n3102\n1748\n2149\n813\n1541\n1556\n2365\n3427\n2152\n7574\n1321\n1573\n839\n2525\n4108\n1463\n1060\n1227\n1004\n647\n1857\n1179\n598\n679\n2088\n4174\n1468\n657\n1549\n934\n1413\n1241\n1061\n1826\n869\n784\n1415\n801\n1309\n1864\n636\n656\n1319\n989\n1024\n1081\n1314\n2325\n952\n1610\n1501\n1145\n1641\n610\n1680\n1710\n1681\n1922\n1113\n1094\n1180\n959\n1776\n777\n2373\n771\n2477\n3174\n565\n1884\n611\n1368\n1420\n1585\n2783\n863\n4932\n1006\n1091\n2927\n1964\n1414\n2567\n512\n2670\n2446\n1221\n2123\n1448\n880\n717\n815\n878\n691\n950\n1336\n516\n2504\n704\n731\n1677\n645\n3099\n3037\n866\n23509\n1770\n1048\n829\n973\n870\n1056\n1571\n684\n936\n1888\n8064\n1019\n4086\n731\n1030\n1201\n946\n1191\n689\n1025\n1909\n1083\n1149\n1112\n3660\n3067\n565\n1131\n1010\n976\n5432\n545\n2423\n670\n1369\n1559\n1643\n567\n1556\n1547\n670\n4161\n4060\n815\n559\n557\n969\n4243\n2274\n14765\n2982\n1904\n975\n1344\n959\n1262\n1243\n1205\n912\n699\n573\n955\n2388\n3128\n601\n642\n1073\n904\n539\n708\n1461\n1321\n566\n1309\n1272\n1434\n777\n1638\n836\n688\n2521\n1789\n1157\n1580\n1410\n1256\n1794\n672\n933\n1263\n989\n5368\n2064\n3819\n3588\n3866\n1800\n1017\n2371\n1642\n3050\n901\n1157\n847\n1015\n1014\n913\n1641\n1614\n1165\n820\n2966\n2559\n1708\n2372\n961\n769\n2666\n3214\n749\n541\n3026\n2459\n1038\n763\n630\n1972\n1811\n1740\n1069\n1670\n2090\n638\n1731\n4949\n2007\n604\n820\n882\n1991\n934\n1289\n1999\n9518\n925\n1499\n1104\n2156\n827\n736\n690\n809\n3484\n1355\n1019\n1301\n2178\n1333\n943\n868\n3277\n1453\n3217\n1731\n720\n649\n1302\n6589\n1526\n913\n5924\n1815\n2135\n941\n847\n807\n5187\n1422\n599\n2333\n2003\n1064\n613\n806\n1206\n1880\n1260\n871\n920\n1472\n1073\n6098\n1467\n528\n1751\n1435\n1004\n1130\n724\n565\n810\n1309\n2646\n5098\n6964\n870\n1819\n899\n1304\n558\n2798\n916\n1838\n3426\n3097\n783\n1985\n2543\n1976\n1871\n1480\n5015\n2620\n4551\n1596\n1712\n864\n568\n1924\n1290\n953\n1673\n3284\n3712\n3401\n1067\n4331\n3527\n2444\n1622\n9723\n864\n631\n770\n654\n853\n654\n8112\n1008\n3829\n1993\n527\n578\n1159\n607\n1207\n1383\n656\n1241\n631\n770\n1057\n1522\n2418\n1460\n1256\n1375\n2088\n3124\n1074\n867\n1424\n622\n2400\n8024\n2738\n3900\n1876\n852\n784\n865\n2097\n1896\n541\n3709\n1515\n1594\n1190\n2001\n737\n1560\n1619\n729\n1395\n4153\n882\n942\n854\n653\n1609\n2195\n655\n935\n2610\n1508\n1088\n849\n948\n620\n1137\n2188\n1443\n615\n994\n832\n1126\n1271\n6214\n2865\n1617\n1962\n1454\n9092\n2401\n831\n609\n1002\n1496\n3517\n2076\n2881\n712\n2035\n529\n2257\n1863\n1548\n1613\n1183\n1101\n1639\n634\n1602\n552\n2454\n1425\n1104\n2775\n4455\n1968\n1425\n1520\n3333\n1885\n2229\n916\n1501\n890\n1207\n1913\n3292\n956\n1353\n1457\n1638\n524\n3366\n977\n1304\n1438\n2439\n6721\n516\n2308\n2323\n1047\n596\n530\n978\n614\n691\n676\n1405\n885\n847\n678\n722\n1544\n1485\n783\n2055\n1231\n1041\n750\n683\n566\n3917\n1346\n4698\n6595\n2722\n4055\n2223\n2114\n1202\n768\n1061\n1149\n1025\n1767\n1306\n1155\n815\n1292\n2528\n1227\n4914\n1806\n5842\n4089\n795\n1957\n1688\n1878\n3875\n995\n613\n1322\n1070\n3728\n1081\n693\n1836\n1293\n3354\n834\n615\n1776\n2012\n6523\n2387\n1271\n1123\n1389\n757\n1818\n1880\n1392\n1890\n1887\n2090\n2271\n1944\n2464\n1764\n1363\n1075\n1043\n1322\n1865\n1943\n3112\n3517\n1234\n802\n820\n6064\n3314\n1359\n677\n920\n565\n4258\n6690\n1417\n2022\n870\n1169\n806\n569\n637\n1910\n1018\n680\n882\n1481\n2944\n1368\n2010\n1820\n1333\n8619\n2140\n1277\n2310\n4510\n2429\n2750\n1314\n622\n695\n1901\n4092\n790\n2919\n1191\n2123\n800\n2827\n677\n1377\n4532\n534\n2643\n5727\n3269\n1635\n1302\n3245\n3028\n2396\n627\n2532\n637\n1323\n1098\n652\n1125\n2286\n2421\n608\n762\n1407\n11195\n1852\n562\n1383\n6609\n1856\n8682\n2808\n3190\n1238\n3876\n3043\n718\n3852\n606\n5753\n2733\n1244\n2797\n5743\n2100\n3177\n1341\n2689\n3263\n1742\n980\n2587\n4125\n4961\n2389\n2445\n1858\n2165\n735\n1389\n1202\n1206\n606\n2487\n2144\n2154\n993\n709\n3485\n1869\n1025\n3760\n1166\n2286\n2222\n2424\n1757\n1670\n6859\n3417\n1282\n526\n1025\n4114\n1722\n10990\n1729\n931\n2995\n730\n767\n2228\n586\n1665\n4237\n3866\n517\n544\n1959\n2009\n1123\n1711\n1191\n3220\n1214\n4433\n1265\n2608\n2263\n2057\n8120\n2515\n2780\n2232\n2542\n2062\n980\n3641\n4889\n1555\n2079\n1809\n557\n1112\n1145\n841\n1431\n1627\n2363\n3272\n2007\n1428\n1216\n1198\n1270\n689\n913\n730\n1191\n4592\n1860\n2374\n614\n596\n711\n1120\n527\n659\n1027\n534\n3294\n671\n5692\n1009\n605\n6490\n1881\n546\n2947\n1141\n1156\n1136\n3030\n2113\n2902\n1029\n4802\n1329\n5983\n1520\n904\n608\n1711\n8531\n2218\n1530\n1049\n1349\n1557\n2216\n676\n1601\n1713\n1371\n1426\n1625\n928\n2261\n896\n2623\n962\n643\n1760\n4868\n699\n930\n1003\n537\n1116\n1009\n1117\n543\n641\n2142\n3994\n7206\n8882\n561\n2180\n965\n1475\n769\n516\n722\n1754\n1073\n910\n890\n3437\n2204\n2544\n5355\n614\n2470\n4095\n1151\n770\n2221\n14162\n1111\n1161\n2946\n2199\n520\n1408\n3963\n4121\n1030\n2108\n2159\n2834\n3560\n6577\n1708\n1326\n590\n1646\n1089\n775\n4231\n9683\n787\n3485\n806\n2539\n1166\n617\n1332\n873\n2648\n1699\n698\n1459\n2254\n732\n11905\n4001\n3666\n2290\n2078\n1486\n2198\n730\n1762\n4153\n736\n1406\n1101\n726\n2055\n2489\n799\n572\n1984\n683\n838\n1985\n1878\n2065\n974\n1516\n554\n3880\n1518\n544\n870\n3568\n546\n1905\n1932\n1952\n1114\n604\n806\n3400\n1337\n2383\n529\n601\n579\n1056\n536\n584\n1715\n1975\n1347\n1258\n694\n4622\n1040\n1741\n577\n1260\n2644\n1357\n1558\n3760\n1289\n749\n728\n594\n521\n779\n1593\n1676\n1340\n2354\n951\n732\n1412\n858\n541\n2066\n660\n1603\n1927\n872\n782\n"
    }
   ],
   "source": [
    "#for t in df[\"text\"]:\n",
    "    #if len(t) > 510:\n",
    "     #   print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\n",
    "        \"../data/models/distiluse/distiluse-base-multilingual-cased\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df_remaining[\"text\"])\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(df_selected[\"text\"])\n",
    "queries_embeddings = embedder.encode(queries, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for query_emb in queries_embeddings:\n",
    "    test = util.semantic_search(\n",
    "        query_embeddings=query_emb,\n",
    "        corpus_embeddings=corpus_embeddings,\n",
    "        query_chunk_size=100,\n",
    "        corpus_chunk_size=100000,\n",
    "        top_k=10,\n",
    "    )\n",
    "    results.append(test)\n",
    "    test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[{&#39;corpus_id&#39;: 2238, &#39;score&#39;: 0.5579902},\n  {&#39;corpus_id&#39;: 1822, &#39;score&#39;: 0.48022944},\n  {&#39;corpus_id&#39;: 2231, &#39;score&#39;: 0.4099578},\n  {&#39;corpus_id&#39;: 2126, &#39;score&#39;: 0.40942243},\n  {&#39;corpus_id&#39;: 22, &#39;score&#39;: 0.4056275},\n  {&#39;corpus_id&#39;: 176, &#39;score&#39;: 0.4022388},\n  {&#39;corpus_id&#39;: 1555, &#39;score&#39;: 0.40112454},\n  {&#39;corpus_id&#39;: 2111, &#39;score&#39;: 0.4001268},\n  {&#39;corpus_id&#39;: 1464, &#39;score&#39;: 0.39807397},\n  {&#39;corpus_id&#39;: 372, &#39;score&#39;: 0.39587364}]]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;Op een diepte van 220 meter is Dinsdagmiddag bij de proefboring te Oostzaan van de Nederlandse Aardolie Maatschappij aardgas aangeboord. Hoewel de aangetroffen hoeveelheid xeer klein is. heeft het toch aan de boring een kleine mogelijkheid gegeven hier later eventueel aardolie aan te treffen.&#39;"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df_selected.iloc[1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;Gistermiddag omstreeks half vier heeft zich bU Centraal Beheer aan de Herengracht te Amsterdam een vrfl hevige explosie voorgedaan. Vermoedelijk door de lekkage in de leiding van een „Buta&quot;-gasfles heeft een der vertrekken zich met het gas gevuld. Toen de automatische oliestookinrichting weer ging branden is het gas door de warmte tot ontploffing gekomen. Er ontstond een begin van brand, dat echter door het personeel met een slang op de waterleiding kon worden geblust. Een 58-jarige kantoorbediende en een 20-jarige monteur werden hierbij licht verwond. Zij werden door de bedrijfsarts verbonden. De explosie vernielde acht ruiten en een muur, die later door de brandweer werd gesloopt. Qverigen viel er voor de brandweer niets te doen.&#39;"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df_remaining.iloc[372][\"text\"]"
   ]
  },
  {
   "source": [
    "# For sentiment analysis system"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text   type\n0                               Aardgas bij Oostzaan  title\n1  Op een diepte van 220 meter is Dinsdagmiddag b...      p\n2  Vier nieuwe boringen in het Duitse petro leumg...      p\n3  &#39;s-GRAVENHAGE, 16 Nov. — Aan de Naamloze Venno...      p\n4  Onmiddellijk na deze toespraken werd weer inge...      p",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aardgas bij Oostzaan</td>\n      <td>title</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Op een diepte van 220 meter is Dinsdagmiddag b...</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Vier nieuwe boringen in het Duitse petro leumg...</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>'s-GRAVENHAGE, 16 Nov. — Aan de Naamloze Venno...</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Onmiddellijk na deze toespraken werd weer inge...</td>\n      <td>p</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/selected_articles/2020-10-07_aardgas.csv\")\n",
    "# This step is necessary to modify the classes into a `list` column\n",
    "# To be used downstream\n",
    "#df[\"list\"] = df[df.columns[\"text\", \"type\"]].values.tolist()\n",
    "new_df = df[[\"text\", \"type\"]].copy()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = \"max_length\"\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MODEL = \"wietsedv/bert-base-dutch-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model - Bertje\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL)\n",
    "model = BertModel.from_pretrained(MODEL)"
   ]
  },
  {
   "source": [
    "Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of dataloaded to the memory and then passed to the neural network needs to be controlled."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.type\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "FULL Dataset: (2565, 2)\nTRAIN Dataset: (2052, 2)\nTEST Dataset: (513, 2)\n"
    }
   ],
   "source": [
    "\n",
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 0\n",
    "            }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 0\n",
    "            }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;batch_sentences&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-31-21da5e5961b4&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m encoded_input = tokenizer(batch_sentences,\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     return_tensors=&quot;pt&quot;)\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&quot;input_ids&quot;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;batch_sentences&#39; is not defined"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(batch_sentences,\n",
    "    # Pad to the longest allowed length by the model \n",
    "    padding=\"max_length\",\n",
    "    # Truncate to maximum length\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\")\n",
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Correct OCR words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import nl_core_news_lg\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import enchant\n",
    "\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from enchant.checker import SpellChecker\n",
    "from difflib import SequenceMatcher\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_original = a\n",
    "text = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+ Op [MASK] Heren Hemelvaartsdag overleed tot onze diepe droefheid   ,    na een langdurig lijden op [MASK] jarige leeft   ,    voorzien van de laatste H   .   H   .    Sacramenten der Stervenden   ,    en in volledige overgave aan Gods H   .    [MASK] [MASK] [MASK] weduwnaar van Mextildns [MASK] Wij bevelen [MASK] ziel in Uwe [MASK]   .    [MASK] aan   .    De bedroefde [MASK] Hnbert [MASK] [MASK] en kinderen Jan [MASK] Wetsels en kinderen Peter Wetsels en kinderen Jan Paas Wetsels en kinderen Charel [MASK] Wetsels en kind Jac   .    Wetsels Brands en kind De plechtige [MASK]   .   dienst gevolgd door de begrafenis zal plaats hebben Maandag [MASK] Mei om 9   .   [MASK] uur in de par   .    kerk te [MASK]   .    [MASK]   .    ten sterf [MASK] om 9 uur   .    [MASK] Zondagavond om 7 uur   .    i &gt; i Voor Uwe [MASK] en vele blijken Van deelneming   ,    betoond bij de ziekte   ,    het overlijden en de begrafenis van onze dierbare broer   ,    zwager   ,    oom en neef   ,    de [MASK]   .    Heer [MASK] [MASK] [MASK] betuigen wij onze hartelijke dank   .    Familie Roex Schinveld   ,    Wilhelminaplein   .    De plechtige [MASK]   .    zal plaats hebben in de par   .    kerk van de H   .    Elifius te Schinveld [MASK] [MASK] Mei a   .   s   .    om 8   .   [MASK] uur   .    — Beleefd verzocht deze te willen bijwonen   .    De plechtige jaardienst voor onze dierbare echtgenoten [MASK] [MASK] [MASK]   .    [MASK] en [MASK] [MASK] [MASK] MARIA [MASK] [MASK]   .    [MASK] zal plaats hebben Donderdag [MASK] Mei a s   .    in de par   .    kerk van de H   .    [MASK] te Weiten om 7   .   [MASK] uur   .    M   .    [MASK] en A   .    [MASK]\n"
    }
   ],
   "source": [
    "rep = { '\\n': ' ', '\\\\': ' ', '\\\"': '\"', '-': ' ', '\"': ' \" ', \n",
    "        '\"': ' \" ', '\"': ' \" ', ',':' , ', '.':' . ', '!':' ! ', \n",
    "        '?':' ? ', \"n't\": \" not\" , \"'ll\": \" will\", '*':' * ', \n",
    "        '(': ' ( ', ')': ' ) ', \"s'\": \"s '\"}\n",
    "rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n",
    "\n",
    "def get_personslist(text):\n",
    "    personslist=[]\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if isinstance(chunk, nltk.tree.Tree) and chunk.label() == 'PERSON':\n",
    "                personslist.insert(0, (chunk.leaves()[0][0]))\n",
    "    return list(set(personslist))\n",
    "\n",
    "personslist = get_personslist(text)\n",
    "\n",
    "ignorewords = personslist + [\"!\", \",\", \".\", \"\\\"\", \"?\", '(', ')', '*', \"'\"]\n",
    "#using enchant.checker.SpellChecker, identify incorrect words\n",
    "d = SpellChecker(\"nl_NL\")\n",
    "words = text.split()\n",
    "incorrectwords = [w for w in words if not d.check(w) and w not in ignorewords]\n",
    "# using enchant.checker.SpellChecker, get suggested replacements\n",
    "suggestedwords = [d.suggest(w) for w in incorrectwords]\n",
    "# replace incorrect words with [MASK]\n",
    "for w in incorrectwords:\n",
    "    text = text.replace(w, '[MASK]')\n",
    "    text_original = text_original.replace(w, '[MASK]')\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load, train and predict using pre-trained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../data/models/bertje\")\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "MASKIDS = [i for i, e in enumerate(tokenized_text) if e == '[MASK]']\n",
    "# Create the segments tensors\n",
    "segs = [i for i, e in enumerate(tokenized_text) if e == \".\"]\n",
    "segments_ids=[]\n",
    "prev=-1\n",
    "for k, s in enumerate(segs):\n",
    "    segments_ids = segments_ids + [k] * (s-prev)\n",
    "    prev=s\n",
    "segments_ids = segments_ids + [len(segs)] * (len(tokenized_text) - len(segments_ids))\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "# prepare Torch inputs \n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "# Load pre-trained model\n",
    "model = AutoModel.from_pretrained(\"../data/models/bertje\")\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    predictions = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-169-bc8e413fed4a&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Predict words for mask using BERT;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 2\u001b[0;31m \u001b[0mtext_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASKIDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m&lt;ipython-input-161-870f1396a09c&gt;\u001b[0m in \u001b[0;36mpredict_word\u001b[0;34m(text_original, predictions, maskids)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMASKIDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 6\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMASKIDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "\n",
    "#Predict words for mask using BERT; \n",
    "def predict_word(text_original, predictions, maskids):\n",
    "    pred_words=[]\n",
    "    for i in range(len(MASKIDS)):\n",
    "        preds = torch.topk(predictions[0, MASKIDS[i]], k=50) \n",
    "        indices = preds.indices.tolist()\n",
    "        list1 = tokenizer.convert_ids_to_tokens(indices)\n",
    "        list2 = suggestedwords[i]\n",
    "        simmax=0\n",
    "        predicted_token=''\n",
    "        for word1 in list1:\n",
    "            for word2 in list2:\n",
    "                s = SequenceMatcher(None, word1, word2).ratio()\n",
    "                if s is not None and s > simmax:\n",
    "                    simmax = s\n",
    "                    predicted_token = word1\n",
    "        text_original = text_original.replace('[MASK]', predicted_token, 1)\n",
    "    return text_original\n",
    "\n",
    "text_original = predict_word(text_original, predictions, MASKIDS)\n",
    "print (text_original)"
   ]
  },
  {
   "source": [
    "# LDA model and TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = nl_core_news_lg.load()\n",
    "\n",
    "# My list of stop words.\n",
    "#stop_list = [\"Mrs.\",\"Ms.\",\"say\",\"WASHINGTON\",\"'s\",\"Mr.\",]\n",
    "\n",
    "# Updates spaCy's default stop words list with my additional words. \n",
    "#nlp.Defaults.stop_words.update(stop_list)\n",
    "\n",
    "# Iterates over the words in the stop words list and resets the \"is_stop\" flag.\n",
    "for word in STOP_WORDS:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatizer(doc):\n",
    "    # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "    \n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2565.0), HTML(value=&#39;&#39;)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53a6908f93d84394b0423d4624147210"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "doc_list = []\n",
    "# Iterates through each article in the corpus.\n",
    "for d in tqdm(doc):\n",
    "    # Passes that article through the pipeline and adds to a new list.\n",
    "    pr = nlp(d)\n",
    "    doc_list.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates, which is a mapping of word IDs to words.\n",
    "words = corpora.Dictionary(doc_list)\n",
    "\n",
    "# Turns each document into a bag of words.\n",
    "corpus = [words.doc2bow(doc) for doc in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=2,\n",
    "                                           update_every=1,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  &#39;0.007*&quot;3&quot; + 0.007*&quot;b&quot; + 0.006*&quot;u.&quot; + 0.006*&quot;ned&quot; + 0.005*&quot;100&quot; + 0.005*&quot;4&quot; + 0.005*&quot;n&quot; + 0.005*&quot;1&quot; + 0.005*&quot;10&quot; + 0.005*&quot;eva&quot;&#39;),\n (1,\n  &#39;0.008*&quot;komen&quot; + 0.007*&quot;twee&quot; + 0.006*&quot;rust&quot; + 0.006*&quot;goed&quot; + 0.006*&quot;minuut&quot; + 0.006*&quot;doelpunt&quot; + 0.005*&quot;gast&quot; + 0.005*&quot;brengen&quot; + 0.005*&quot;weten&quot; + 0.004*&quot;gaan&quot;&#39;),\n (2,\n  &#39;0.016*&quot;ƒ&quot; + 0.015*&quot;1&quot; + 0.012*&quot;2&quot; + 0.011*&quot;■&quot; + 0.010*&quot;tel&quot; + 0.010*&quot;f&quot; + 0.009*&quot;koop&quot; + 0.009*&quot;ét&quot; + 0.009*&quot;no.&quot; + 0.008*&quot;br&quot;&#39;),\n (3,\n  &#39;0.007*&quot;komen&quot; + 0.006*&quot;goed&quot; + 0.006*&quot;groot&quot; + 0.005*&quot;één&quot; + 0.005*&quot;gaan&quot; + 0.005*&quot;jaar&quot; + 0.004*&quot;zien&quot; + 0.004*&quot;zeggen&quot; + 0.004*&quot;maken&quot; + 0.004*&quot;staan&quot;&#39;),\n (4,\n  &#39;0.016*&quot;g&quot; + 0.012*&quot;j.&quot; + 0.011*&quot;1950&quot; + 0.010*&quot;mei&quot; + 0.009*&quot;h.&quot; + 0.006*&quot;a.&quot; + 0.005*&quot;uur&quot; + 0.005*&quot;overlijden&quot; + 0.004*&quot;b&quot; + 0.004*&quot;fan&quot;&#39;),\n (5,\n  &#39;0.018*&quot;mrs&quot; + 0.011*&quot;mr&quot; + 0.007*&quot;j&quot; + 0.004*&quot;afgel&quot; + 0.004*&quot;|&quot; + 0.003*&quot;john&quot; + 0.003*&quot;ballon&quot; + 0.003*&quot;bezoeken&quot; + 0.002*&quot;mr.&quot; + 0.002*&quot;kerk&quot;&#39;),\n (6,\n  &#39;0.044*&quot;v&quot; + 0.019*&quot;n&quot; + 0.009*&quot;■&quot; + 0.007*&quot;17&quot; + 0.007*&quot;28&quot; + 0.007*&quot;25&quot; + 0.006*&quot;18&quot; + 0.006*&quot;mei&quot; + 0.006*&quot;p&quot; + 0.006*&quot;26&quot;&#39;),\n (7,\n  &#39;0.006*&quot;krant&quot; + 0.006*&quot;gast&quot; + 0.005*&quot;heer&quot; + 0.004*&quot;nederlands&quot; + 0.004*&quot;minister&quot; + 0.004*&quot;regering&quot; + 0.004*&quot;amsterdam&quot; + 0.004*&quot;land&quot; + 0.003*&quot;wensen&quot; + 0.003*&quot;groot&quot;&#39;),\n (8,\n  &#39;0.032*&quot;■&quot; + 0.009*&quot;&gt;&quot; + 0.006*&quot;1&quot; + 0.006*&quot;j&quot; + 0.005*&quot;n&quot; + 0.005*&quot;v&quot; + 0.004*&quot;&lt;&quot; + 0.004*&quot;k&quot; + 0.004*&quot;f&quot; + 0.004*&quot;m&quot;&#39;),\n (9,\n  &#39;0.035*&quot;3&quot; + 0.018*&quot;100&quot; + 0.015*&quot;4&quot; + 0.015*&quot;31&quot; + 0.008*&quot;101&quot; + 0.006*&quot;102&quot; + 0.006*&quot;96&quot; + 0.005*&quot;99&quot; + 0.005*&quot;34&quot; + 0.005*&quot;97&quot;&#39;)]"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}