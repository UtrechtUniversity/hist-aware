{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-12 15:52:38,125 — parsers — DEBUG — Test message\n",
      "2020-10-12 15:52:38,125 — parsers — DEBUG — Test message\n",
      "2020-10-12 15:52:38,127 — iterators — DEBUG — Test message\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries needed\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/leonardovida/dev/HistAware\")\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, util\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from src import iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the model - Bertje\n",
    "tokenizer = BertTokenizer.from_pretrained(\"wietsedv/bert-base-dutch-cased\")\n",
    "model = BertModel.from_pretrained(\"wietsedv/bert-base-dutch-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the file\n",
    "csv = iterators.iterate_directory(\"../data/processed/selected_articles/\", \".csv\")\n",
    "df = pd.concat([pd.read_csv(c[\"article_path\"]) for c in csv],ignore_index=True)\n",
    "df.sort_values(by=[\"count\"], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[0:100]\n",
    "df_remaining = df[101:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\n",
    "        \"../data/models/distiluse/distiluse-base-multilingual-cased\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df_remaining[\"text\"])\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(df_selected[\"text\"])\n",
    "queries_embeddings = embedder.encode(queries, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for query_emb in queries_embeddings:\n",
    "    test = util.semantic_search(\n",
    "        query_embeddings=query_emb,\n",
    "        corpus_embeddings=corpus_embeddings,\n",
    "        query_chunk_size=100,\n",
    "        corpus_chunk_size=100000,\n",
    "        top_k=10,\n",
    "    )\n",
    "    results.append(test)\n",
    "    test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 56, 'score': 1.0000002},\n",
       "  {'corpus_id': 1191, 'score': 0.46423584},\n",
       "  {'corpus_id': 1001, 'score': 0.46423584},\n",
       "  {'corpus_id': 169, 'score': 0.46423584},\n",
       "  {'corpus_id': 4795, 'score': 0.4443941},\n",
       "  {'corpus_id': 1085, 'score': 0.4443941},\n",
       "  {'corpus_id': 2554, 'score': 0.4293515},\n",
       "  {'corpus_id': 887, 'score': 0.42333776},\n",
       "  {'corpus_id': 13, 'score': 0.42276603},\n",
       "  {'corpus_id': 3721, 'score': 0.41876274}]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ning tijdens de ontgassing normaal kan doorgaan. In de Belgische mijn „Le Grand Trait\" te Frameries in Henegouwen „oogstte\" men op deze wijze in 2 maanden tijds 378.000 m 3 methaangas, in de mijn „Saint Albert\" te Ressaix in een iets langere periode 428.650 m 3 methaan. In Henegouwen wordt het gas reeds naar buiten geleverd via de lichtgasfabrieken te Tertre. Methaangas levert 8000 tot 9000 caloriën warmte, hetgeen tweemaal zoveel is als gewoon cokesovengas. In vele andere mijnen, waaronder de Kempische, neemt men proeven. Er bestaan plannen in Belgisch Limburg een leidingermet aan te leggen voor de distributie van het gas aan de bevolking. Een probleem vormt echter de vrij onregelmatige toevoer, waarmee men ongetwijfeld te kampen zal krijgen. In de mijn Hirschbach in het Saargebied heeft men een andere methode gevolgd. In deze mijn ontsnapte zoveel gas dat met luchtverversing niet voldoende te bereiken was. Een gedeelte van de mijn werd daarom met dammen van de rest afgesloten. Door hel verrichten van boringen en door het afbouwen van een dieper gelegen laag zorgde men er voor, dat het gas naar de afgesloten ruimte ontsnapte. Hieruit werd het weggezogen om bovengronds te worden gebruikt voor de verhitting van een stoomketel. De besparing bedroeg 500 ton kolen per maand. In ruim 11 jaar won men in Hirschbach 5 millioen in 3 mijngas. Voordelen Technisch gesproken heeft men al veel bereikt. Er blijven echter nog problemen, die om een oplossing vragen. Het lijdt echter geen twijfel, dat men op het goede spoor is. Aan de mijngas-winning zijn vele voordelen verbonden. In het ene mijnbekken zal een bepaald voordeel zwaarder wegen dan in het andere, maar in het algemeen zijn het de volgende. Door het gas te winnen voordat het in pijlers en mijngangen terecht komt, wordt de veiligheid in het ondergronds bedrijf verhoogd. De kans op vorming van ontplofbare mengsels wordt veel kleiner. Hiermee wordt het belang van de mijnwerkers gediend. In een buitenlandse mijn daalde het gasgehalte van de uittrekkende luchtstroom op deze manier van 2 of 3 percent tot beneden 1 percent. Daarnaast is er een economisch voordeel, dat niet alleen voor de mijnwerkers, maar ook voor een veel grotere groep mensen van belang is. Het gas kan worden gebruikt voor de voorziening van industrieën en woningen. Met het mijngas, dat nu dagelijks uit onze mijnen wordt geblazen, zouden zeker tienduizenden huismoeders hun potje kunnen koken. Een andere mogelijkheid is dat het als stookgas wordt gebruikt in ketels, waardoor kolen worden bespaard. En dan zullen er zeker chemische fabrieken zijn die er nuttige producten van kunnen maken. Voor de mijnen zelf zijn er ook speciale voordelen verbonden aan de ontgassing. Het komt vaak voor dat de koolwinning wordt gehandicapt door het ontsnappen van mijngas. Het kan zijn dat van een bepaalde pijler gemakkelijk 1000 ton kolen per dag kunnen worden getrokken, terwijl men er toch niet meer dan 500 ton uithaalt, omdat anders het mijngasgehalte in de luchtstroom boven het voorgeschreven peil stijgt. Wordt de betreffende kolenlaag voor of tijdens de exploitatie ontgast, dan kan men zonder bezwaar de productie opvoeren. Dat is een kwestie van meer mensen. Dit voordeel noemt men: een grotere concentratie van de ontginning. Deze doet de kostprijs per ton dalen. Ten slotte is daar f N De moderne gestroomlijnde schacht van Staatsmijn Emma, waardoor per aur 500 ton kool van 546 meter dieptt naar boven wordt gebracht -\"* -•-•■ \\'•■ _■ _,*<£_&_ ■■■■■-■ \\'fTÜlfc\\'in •■:-\\' ■\\' ...*......->...'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.iloc[1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HST AANBOREN van gas bU Coevorden heeft tot deze boring b\\\\j Gramsbergen geleid. Waar gas zit, zit dikwijls ook olie en olie is tenslotte de voornaamste prooi, waarop wordt geloerd. Ook gas kan echter van grote betekenis zijn. De succesvolle boringen bU Coevorden, en later bij de Wijk (bü Meppel) hebben al een stroom van geruchten door Drente, Overijssel en Groningen doen gaan. Men sprak al van een stad (Assen), die haar gasbedrijf per 1 Januari j.L op het aardgas van de „Nam\" zou overschakelen. Men vertelde van Groningen en andere plaatsen, die de uitbreidingsplannen voor hun gasfabrieken reeds ter zijde zouden hebben gelegd, omdat de productie van aardgas grootse perspectieven zou hebben geopend. Natuurlijk is dat alles ontzaggelijk overdreven. Vooralsnog hebben de onderzoekers van de .Nam\\' het plan om eventueel te vinden gas te gebruiken voor het gemakkelijker naar boven brengen van de olie. Gelijk bekend, zijn er elders ter wereld verschillende spui-'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remaining.iloc[1191][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For sentiment analysis system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = \"max_length\"\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MODEL = \"wietsedv/bert-base-dutch-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model - Bertje\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL)\n",
    "model = BertModel.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of dataloaded to the memory and then passed to the neural network needs to be controlled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.type\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2565, 2)\n",
      "TRAIN Dataset: (2052, 2)\n",
      "TEST Dataset: (513, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 0\n",
    "            }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 0\n",
    "            }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name &#39;batch_sentences&#39; is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-31-21da5e5961b4&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m encoded_input = tokenizer(batch_sentences,\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     return_tensors=&quot;pt&quot;)\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&quot;input_ids&quot;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;batch_sentences&#39; is not defined"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(batch_sentences,\n",
    "    # Pad to the longest allowed length by the model \n",
    "    padding=\"max_length\",\n",
    "    # Truncate to maximum length\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\")\n",
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA model and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = nl_core_news_lg.load()\n",
    "\n",
    "# My list of stop words.\n",
    "#stop_list = [\"Mrs.\",\"Ms.\",\"say\",\"WASHINGTON\",\"'s\",\"Mr.\",]\n",
    "\n",
    "# Updates spaCy's default stop words list with my additional words. \n",
    "#nlp.Defaults.stop_words.update(stop_list)\n",
    "\n",
    "# Iterates over the words in the stop words list and resets the \"is_stop\" flag.\n",
    "for word in STOP_WORDS:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatizer(doc):\n",
    "    # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "    \n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a6908f93d84394b0423d4624147210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2565.0), HTML(value=&#39;&#39;)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_list = []\n",
    "# Iterates through each article in the corpus.\n",
    "for d in tqdm(doc):\n",
    "    # Passes that article through the pipeline and adds to a new list.\n",
    "    pr = nlp(d)\n",
    "    doc_list.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates, which is a mapping of word IDs to words.\n",
    "words = corpora.Dictionary(doc_list)\n",
    "\n",
    "# Turns each document into a bag of words.\n",
    "corpus = [words.doc2bow(doc) for doc in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=2,\n",
    "                                           update_every=1,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  &#39;0.007*&quot;3&quot; + 0.007*&quot;b&quot; + 0.006*&quot;u.&quot; + 0.006*&quot;ned&quot; + 0.005*&quot;100&quot; + 0.005*&quot;4&quot; + 0.005*&quot;n&quot; + 0.005*&quot;1&quot; + 0.005*&quot;10&quot; + 0.005*&quot;eva&quot;&#39;),\n",
       " (1,\n",
       "  &#39;0.008*&quot;komen&quot; + 0.007*&quot;twee&quot; + 0.006*&quot;rust&quot; + 0.006*&quot;goed&quot; + 0.006*&quot;minuut&quot; + 0.006*&quot;doelpunt&quot; + 0.005*&quot;gast&quot; + 0.005*&quot;brengen&quot; + 0.005*&quot;weten&quot; + 0.004*&quot;gaan&quot;&#39;),\n",
       " (2,\n",
       "  &#39;0.016*&quot;ƒ&quot; + 0.015*&quot;1&quot; + 0.012*&quot;2&quot; + 0.011*&quot;■&quot; + 0.010*&quot;tel&quot; + 0.010*&quot;f&quot; + 0.009*&quot;koop&quot; + 0.009*&quot;ét&quot; + 0.009*&quot;no.&quot; + 0.008*&quot;br&quot;&#39;),\n",
       " (3,\n",
       "  &#39;0.007*&quot;komen&quot; + 0.006*&quot;goed&quot; + 0.006*&quot;groot&quot; + 0.005*&quot;één&quot; + 0.005*&quot;gaan&quot; + 0.005*&quot;jaar&quot; + 0.004*&quot;zien&quot; + 0.004*&quot;zeggen&quot; + 0.004*&quot;maken&quot; + 0.004*&quot;staan&quot;&#39;),\n",
       " (4,\n",
       "  &#39;0.016*&quot;g&quot; + 0.012*&quot;j.&quot; + 0.011*&quot;1950&quot; + 0.010*&quot;mei&quot; + 0.009*&quot;h.&quot; + 0.006*&quot;a.&quot; + 0.005*&quot;uur&quot; + 0.005*&quot;overlijden&quot; + 0.004*&quot;b&quot; + 0.004*&quot;fan&quot;&#39;),\n",
       " (5,\n",
       "  &#39;0.018*&quot;mrs&quot; + 0.011*&quot;mr&quot; + 0.007*&quot;j&quot; + 0.004*&quot;afgel&quot; + 0.004*&quot;|&quot; + 0.003*&quot;john&quot; + 0.003*&quot;ballon&quot; + 0.003*&quot;bezoeken&quot; + 0.002*&quot;mr.&quot; + 0.002*&quot;kerk&quot;&#39;),\n",
       " (6,\n",
       "  &#39;0.044*&quot;v&quot; + 0.019*&quot;n&quot; + 0.009*&quot;■&quot; + 0.007*&quot;17&quot; + 0.007*&quot;28&quot; + 0.007*&quot;25&quot; + 0.006*&quot;18&quot; + 0.006*&quot;mei&quot; + 0.006*&quot;p&quot; + 0.006*&quot;26&quot;&#39;),\n",
       " (7,\n",
       "  &#39;0.006*&quot;krant&quot; + 0.006*&quot;gast&quot; + 0.005*&quot;heer&quot; + 0.004*&quot;nederlands&quot; + 0.004*&quot;minister&quot; + 0.004*&quot;regering&quot; + 0.004*&quot;amsterdam&quot; + 0.004*&quot;land&quot; + 0.003*&quot;wensen&quot; + 0.003*&quot;groot&quot;&#39;),\n",
       " (8,\n",
       "  &#39;0.032*&quot;■&quot; + 0.009*&quot;&gt;&quot; + 0.006*&quot;1&quot; + 0.006*&quot;j&quot; + 0.005*&quot;n&quot; + 0.005*&quot;v&quot; + 0.004*&quot;&lt;&quot; + 0.004*&quot;k&quot; + 0.004*&quot;f&quot; + 0.004*&quot;m&quot;&#39;),\n",
       " (9,\n",
       "  &#39;0.035*&quot;3&quot; + 0.018*&quot;100&quot; + 0.015*&quot;4&quot; + 0.015*&quot;31&quot; + 0.008*&quot;101&quot; + 0.006*&quot;102&quot; + 0.006*&quot;96&quot; + 0.005*&quot;99&quot; + 0.005*&quot;34&quot; + 0.005*&quot;97&quot;&#39;)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-thesis-Op-asMvu-py3.8",
   "language": "python",
   "name": "paper-thesis-op-asmvu-py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
