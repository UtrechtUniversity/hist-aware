{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "preliminary-hawaiian",
   "metadata": {},
   "source": [
    "# Process selected labeled data and create DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "satisfied-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset as DT\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import (AutoModel, AutoTokenizer, AutoConfig,\n",
    "                          Trainer, TrainingArguments)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import wandb\n",
    "\n",
    "import nltk.data\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import alpino\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "designed-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "opened-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'wietsedv/bert-base-dutch-cased'\n",
    "LEN_SENTS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-serve",
   "metadata": {},
   "source": [
    "## Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "mighty-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols = ['sentiment', 'text', 'energy', 'article_filepath', 'article_name', 'count', 'date', 'dir', 'index_article', 'index_metadata', 'metadata_filepath',\n",
    "                    'newspaper_language', 'newspaper_publisher', 'newspaper_source', 'newspaper_title', 'newspaper_volume', \n",
    "             'newspaper_issuenumber', 'newspaper_city', 'text_clean', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "rough-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    \"\"\"Function to clean df after concat\"\"\"\n",
    "    df.text.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    df.labels.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['labels'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-preliminary",
   "metadata": {},
   "source": [
    "### Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "supposed-seating",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gas_1980 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1980s_gas.csv\")\n",
    "gas_1990 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1990s_gas_labeled.csv\")\n",
    "\n",
    "gas_1980 = gas_1980[list_cols]\n",
    "gas_1990 = gas_1990[list_cols]\n",
    "\n",
    "gas = gas_1980.append(gas_1990, ignore_index=True)\n",
    "gas = gas[gas.energy == \"Y\"]\n",
    "gas = gas[gas.sentiment != None]\n",
    "gas.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "gas = clean_df(gas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-antigua",
   "metadata": {},
   "source": [
    "### Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "driving-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_1980 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1980s_oil.csv\")\n",
    "oil_1990 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1990s_olie_labeled.csv\")\n",
    "\n",
    "oil_1980 = oil_1980[list_cols]\n",
    "oil_1990 = oil_1980[list_cols]\n",
    "\n",
    "oil = oil_1980.append(oil_1990, ignore_index=True)\n",
    "oil = oil[oil.energy == \"Y\"]\n",
    "oil = oil[oil.sentiment != None]\n",
    "oil.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "oil = clean_df(oil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-footage",
   "metadata": {},
   "source": [
    "### Coal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "advanced-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_1980 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1980s_coal.csv\")\n",
    "coal_1990 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1990s_kool_labeled.csv\")\n",
    "coal_1990.drop([\"sentiment_gas\", \"sentiment_oil\"], axis=1, inplace=True)\n",
    "coal_1990.rename(columns = {\"sentiment\": \"accuracy_selection\", \"sentiment_coal\": \"sentiment\"}, inplace=True)\n",
    "\n",
    "coal_1980 = coal_1980[list_cols]\n",
    "coal_1990 = coal_1990[list_cols]\n",
    "\n",
    "coal = coal_1980.append(coal_1990, ignore_index=True)\n",
    "coal = coal[coal.energy == \"Y\"]\n",
    "coal = coal[coal.sentiment != None]\n",
    "coal.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "coal = clean_df(coal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-clothing",
   "metadata": {},
   "source": [
    "### General df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "nutritional-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2773, 20)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([gas, oil, coal], ignore_index=True)\n",
    "df = clean_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-pierre",
   "metadata": {},
   "source": [
    "## Fix labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "expanded-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_sentiment = {\"labels\": {\"VN\": 1, \"NG\": 2, \"NE\": 3, \"PO\": 4, \"VP\": 5}}\n",
    "oil = oil.replace(cleanup_sentiment)\n",
    "gas = gas.replace(cleanup_sentiment)\n",
    "coal = coal.replace(cleanup_sentiment)\n",
    "df = df.replace(cleanup_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cognitive-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(df.sentiment)\n",
    "#plt.xlabel('review sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-march",
   "metadata": {},
   "source": [
    "Reduce from 5 labels to 3 because of lack of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "excited-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(rating):\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 0\n",
    "    elif rating == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['labels'] = df.labels.apply(to_sentiment)\n",
    "gas['labels'] = gas.labels.apply(to_sentiment)\n",
    "coal['labels'] = coal.labels.apply(to_sentiment)\n",
    "oil['labels'] = oil.labels.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "european-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(df.sentiment)\n",
    "#plt.xlabel('review sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mistake",
   "metadata": {},
   "source": [
    "### Split text and explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "tropical-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite(l, n):\n",
    "    \"\"\"Unite sentences previously split using nltk.tokenize.\"\"\"\n",
    "    count = []\n",
    "    chunks = []\n",
    "    sents = []\n",
    "    for s in l:\n",
    "        count.append(len(s.split()))\n",
    "    value = 0\n",
    "    prev_idx = 0\n",
    "    for i in range(0, len(count)):\n",
    "        if value == 0:\n",
    "            value = value + count[i]\n",
    "        elif (i+1 == len(count)):\n",
    "            chunks.append(l[prev_idx:i])\n",
    "            value = 0\n",
    "        elif value >= n:\n",
    "            chunks.append(l[prev_idx:i])\n",
    "            prev_idx = i\n",
    "            value = 0\n",
    "        else:\n",
    "             value = value + count[i]\n",
    "    for c in chunks:\n",
    "        sents.append(' '.join(c))\n",
    "    return(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "toxic-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(s, n):\n",
    "    \"\"\"Split sentences only using the number of words.\"\"\"\n",
    "    pieces = s.split()\n",
    "    return [\" \".join(pieces[i:i+n]) for i in range(0, len(pieces), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "light-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_split_text(df):\n",
    "    df[\"text_split\"] = df[\"text\"].apply(sent_tokenize)\n",
    "    df[\"text_split\"] = df[\"text_split\"].apply(unite, n = LEN_SENTS)\n",
    "    df.text_split.replace([], np.nan, inplace=True)\n",
    "    df.dropna(subset=['text_split'], inplace=True)\n",
    "    # Cancel all text_split == 0\n",
    "    df.drop(df[df.text_split.map(len) == 0].index, inplace=True)\n",
    "    # Currently not splitting the cleaned sentences\n",
    "    #df[\"text_clean_split\"] = df[\"text_clean\"].apply(splitter, n = LEN_SENTS)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "worse-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = apply_split_text(oil)\n",
    "gas = apply_split_text(gas)\n",
    "coal = apply_split_text(coal)\n",
    "df = apply_split_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-horizontal",
   "metadata": {},
   "source": [
    "Explode the sentences that we created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "wireless-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('text_split')\n",
    "gas = gas.explode('text_split')\n",
    "coal = coal.explode('text_split')\n",
    "oil = oil.explode('text_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "harmful-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"~/dev/hist-aware/notebooks/sentiment/df.csv\")\n",
    "gas.to_csv(\"~/dev/hist-aware/notebooks/sentiment/gas.csv\")\n",
    "coal.to_csv(\"~/dev/hist-aware/notebooks/sentiment/coal.csv\")\n",
    "oil.to_csv(\"~/dev/hist-aware/notebooks/sentiment/oil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-franchise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histaware-NidRwJ64-py3.8",
   "language": "python",
   "name": "histaware-nidrwj64-py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
