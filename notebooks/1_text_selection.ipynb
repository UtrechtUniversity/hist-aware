{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links to Project Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Trello board](https://trello.com/invite/b/BWnRAtKJ/3e7ce03017000289323e762d0ed2e304/histaware)\n",
    "- [Notion Wiki](https://www.notion.so/HistAware-529aba41f84946b19d493394ef6a2748)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text",
     "selection",
     "xml",
     "transformers"
    ]
   },
   "source": [
    "# Part I: Text selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first phase of the project, we approach the first problem of selecting texts similar texts. Intially the scope of the research is focused on texts that deal with `energy`. However, this scope might change and/or might be expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phases of Part I:**\n",
    "- **Validate the approach to the project**:\n",
    "    1. Decide whether to use title and paragraphs or only one of the two\n",
    "    2. Find the most efficient way to read all the xml files\n",
    "    3. Begin to label a golden set of texts that are within the scope of the research AND select the most important keywords that will be used to search for similar texts\n",
    "    4. Run the text similarity ML algorithm\n",
    "    5. Have the teaching assistant go throught the selection and identify mistakes\n",
    "- **To think about**: how to keep the relevant information about the text fragment (i.e. newspaper origin and date)?\n",
    "- **Decide the tools to use for text selection**. Current choices are:\n",
    "    - Use `sentence-transformers` from UKPLab (https://github.com/UKPLab/sentence-transformers)\n",
    "        - Generate embeddings on sentences (max 512 words)\n",
    "        - Find similar texts\n",
    "    - Use `faiss` from Facebook AI (https://github.com/facebookresearch/faiss)\n",
    "        - Less documentation but seemingly more scalable\n",
    "    - Use ASReview from Utrecht University ()\n",
    "        - A meeting with Jonathan or Raul is necessary to understand the feasibility of this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output, Markdown\n",
    "import pathlib\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/Users/leonardovida/dev/HistAware\")\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import xml.etree.ElementTree as et \n",
    "import collections\n",
    "from itertools import chain\n",
    "import nl_core_news_lg\n",
    "from datetime import datetime\n",
    "\n",
    "# Import created modules\n",
    "from src import text_selection\n",
    "from src import iterators\n",
    "from src import parsers\n",
    "from src import logger\n",
    "\n",
    "# Config for jupyter\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"/Users/leonardovida/dev/HistAware/\"\n",
    "# Data path for Delpher data\n",
    "DIR_PATH = os.path.join(FILE_PATH, \"data\", \"1950\", \"Delpher\")\n",
    "# Save path\n",
    "SAVE_PATH = os.path.join(FILE_PATH, \"data\", \"processed\")\n",
    "# Decide whether to ungizip metadata\n",
    "UNGIZP = False\n",
    "# Decide whether to process and save articles and metadata data\n",
    "DATAFILE = False\n",
    "# Keywords to use for the naive text selection\n",
    "KEYWORDS = [\"olie\", \"aardgas\", \"steenkool\"]\n",
    "# Number of synonyms to retrieve for each keyword, the more the less accurate\n",
    "NUM_SYNONYMS = 50\n",
    "# Transformer model to use for the creation of the synonyms\n",
    "NLP = nl_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Find path and name of saved articles\n"
    }
   ],
   "source": [
    "# Find path and name of saved data\n",
    "print(\"Find path and name of saved articles\")\n",
    "csv_articles = iterators.iterate_directory(\n",
    "    dir_path=os.path.join(SAVE_PATH, \"processed_articles\"), file_type=\".csv\"\n",
    ")\n",
    "csv_articles = pd.DataFrame(csv_articles)\n",
    "csv_articles.rename(\n",
    "    {\n",
    "        \"article_name\": \"csv_name\",\n",
    "        \"article_path\": \"csv_path\",\n",
    "        \"article_dir\": \"csv_dir\",\n",
    "    },\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Find path and name of saved metadata\n"
    }
   ],
   "source": [
    "print(\"Find path and name of saved metadata\")\n",
    "csv_metadata = iterators.iterate_directory(\n",
    "    dir_path=os.path.join(SAVE_PATH, \"processed_metadata\"), file_type=\".csv\"\n",
    ")\n",
    "csv_metadata = pd.DataFrame(csv_metadata)\n",
    "csv_metadata.rename(\n",
    "    {\n",
    "        \"article_name\": \"csv_name\",\n",
    "        \"article_path\": \"csv_path\",\n",
    "        \"article_dir\": \"csv_dir\",\n",
    "    },\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for index, row in csv_metadata.iterrows():\n",
    "    csv_file = pd.read_csv(row[\"csv_path\"])\n",
    "    li.append(csv_file)\n",
    "df_metadata = pd.concat(li, axis=0)\n",
    "df_metadata.drop([\"level_0\", \"date\"], axis=1, inplace=True)\n",
    "df_metadata.rename(\n",
    "    {\"filepath\": \"metadata_filepath\", \"index\": \"index_metadata\"},\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_selection.py\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def search_synonyms(nlp, word, df, n):\n",
    "    \"\"\"Find all texts in which a synonym of the word appears.\n",
    "\n",
    "    Takes:\n",
    "        - string (word)\n",
    "        - dataframe in which to search\n",
    "        - The total number of synonym to retrieve\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    ms = nlp.vocab.vectors.most_similar(\n",
    "        np.asarray([nlp.vocab.vectors[nlp.vocab.strings[word]]]), n=n\n",
    "    )\n",
    "    synonyms = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "    print(f\"Searching using the following synonyms of {word}:\")\n",
    "    print(synonyms)\n",
    "    df.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "    for syn in tqdm(synonyms):\n",
    "        df = df[df[\"text\"].str.contains(syn, case=False, regex=False)]\n",
    "        df[\"count\"] = df[\"text\"].str.count(syn)\n",
    "        #count=sum(1 for _ in re.finditer(r\"\\b%s\\b\" % re.escape(word), syn)),\n",
    "        result = result.append(df)\n",
    "    return result\n",
    "\n",
    "def select_articles(nlp, word, df, n):\n",
    "    res = search_synonyms(nlp, word, df, n)\n",
    "\n",
    "    # Drop duplicates to keep only individual articles\n",
    "    res.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Searching synonyms\nSearching synonym olie\n  0%|          | 0/50 [00:00&lt;?, ?it/s]Searching using the following synonyms of olie:\n[&#39;olie&#39;, &#39;-olie&#39;, &#39;olieen&#39;, &#39;olies&#39;, &#39;wokolie&#39;, &#39;MCT-olie&#39;, &#39;bakolie&#39;, &#39;olieën&#39;, &#39;cocosolie&#39;, &#39;smeerolie&#39;, &#39;paraffineolie&#39;, &#39;maïsolie&#39;, &#39;remolie&#39;, &#39;castorolie&#39;, &#39;rijstolie&#39;, &#39;bio-olie&#39;, &#39;olien&#39;, &#39;schalieolie&#39;, &#39;citrusolie&#39;, &#39;spijsolie&#39;, &#39;Gasolie&#39;, &#39;ricinusolie&#39;, &#39;slaolie&#39;, &#39;maisolie&#39;, &#39;zaadolie&#39;, &#39;kruidenolie&#39;, &#39;boterolie&#39;, &#39;kruidnagelolie&#39;, &#39;aardolie&#39;, &#39;Badolie&#39;, &#39;koolzaadolie&#39;, &#39;citroenolie&#39;, &#39;soja-olie&#39;, &#39;mosterdolie&#39;, &#39;teakolie&#39;, &#39;Smeerolie&#39;, &#39;sesamolie&#39;, &#39;oliën&#39;, &#39;dieselolie&#39;, &#39;palmpitolie&#39;, &#39;arachideolie&#39;, &#39;kokosnootolie&#39;, &#39;kokosolie&#39;, &#39;badolie&#39;, &#39;plantenolie&#39;, &#39;algenolie&#39;, &#39;huidolie&#39;, &#39;kaneelolie&#39;, &#39;schalie-olie&#39;, &#39;baardolie&#39;]\n100%|██████████| 50/50 [00:00&lt;00:00, 72.12it/s]\nSearching synonym aardgas\n  0%|          | 0/50 [00:00&lt;?, ?it/s]Searching using the following synonyms of aardgas:\n[&#39;aardgas&#39;, &#39;aardgas-&#39;, &#39;aardgasnet&#39;, &#39;aardgasgestookte&#39;, &#39;aardgasketel&#39;, &#39;Aardgas&#39;, &#39;aardgascondensaat&#39;, &#39;aardgasmotor&#39;, &#39;aardgasverbruik&#39;, &#39;aardgasbuffer&#39;, &#39;aardgasveld&#39;, &#39;gas&#39;, &#39;aardgasnetwerk&#39;, &#39;aardgasloos&#39;, &#39;aardgasnetbeheerder&#39;, &#39;aardgasprijs&#39;, &#39;aardgasprijzen&#39;, &#39;aardgasvelden&#39;, &#39;aardgasvervoersnet&#39;, &#39;aardgaswinning&#39;, &#39;elektriciteit&#39;, &#39;elektriciteitstoevoer&#39;, &#39;aardgasleiding&#39;, &#39;aardgasmarkt&#39;, &#39;elektriciteitsopwekking&#39;, &#39;stookolie&#39;, &#39;elektriciteits&#39;, &#39;elektriciteitsproductie&#39;, &#39;elektriciteit-&#39;, &#39;elektriciteitscentrales&#39;, &#39;aardgasloze&#39;, &#39;aardgasleidingen&#39;, &#39;warmtekrachtcentrales&#39;, &#39;elektriciteits-&#39;, &#39;aardgasbaten&#39;, &#39;aardgasaansluiting&#39;, &#39;elektriciteitsverbruik&#39;, &#39;elektriciteitsprijs&#39;, &#39;elektriciteitsprijzen&#39;, &#39;electriciteitsverbruik&#39;, &#39;Biobrandstof&#39;, &#39;biomassacentrales&#39;, &#39;elektriciteitsvraag&#39;, &#39;dieselbrandstof&#39;, &#39;elektriciteitsnet&#39;, &#39;biomassaketel&#39;, &#39;brandstoffen&#39;, &#39;elektriciteitslevering&#39;, &#39;elektriciteitsproducent&#39;, &#39;elektriciteitsnetten&#39;]\n100%|██████████| 50/50 [00:00&lt;00:00, 84.17it/s]\nSearching synonym steenkool\n  0%|          | 0/50 [00:00&lt;?, ?it/s]Searching using the following synonyms of steenkool:\n[&#39;steenkool&#39;, &#39;steenkool-&#39;, &#39;steenkolen&#39;, &#39;steenkoolgas&#39;, &#39;steenkoollagen&#39;, &#39;steenkoolwinning&#39;, &#39;kolen&#39;, &#39;steenkoolteer&#39;, &#39;steenkoolmijnen&#39;, &#39;bruinkool&#39;, &#39;steenkolenmijnen&#39;, &#39;steenkoolcentrales&#39;, &#39;ijzererts&#39;, &#39;steenkoolbekken&#39;, &#39;steenkolenmijn&#39;, &#39;Steenkool&#39;, &#39;steenkoolindustrie&#39;, &#39;steenkoolcentrale&#39;, &#39;steenkoolmijn&#39;, &#39;aardolie&#39;, &#39;bruinkoolwinning&#39;, &#39;steenkolenengels&#39;, &#39;kolenzandsteen&#39;, &#39;bruinkoolcentrales&#39;, &#39;mijnbouw&#39;, &#39;steengroeven&#39;, &#39;ertsen&#39;, &#39;erts&#39;, &#39;kolenmijnen&#39;, &#39;hoogovens&#39;, &#39;kolenwinning&#39;, &#39;steenzout&#39;, &#39;hoogoven&#39;, &#39;w.b&#39;, &#39;grondstof&#39;, &#39;aardgas&#39;, &#39;steengroeves&#39;, &#39;kalksteengroeven&#39;, &#39;steenkoude&#39;, &#39;aardolie-industrie&#39;, &#39;staalfabrieken&#39;, &#39;hoogovenslakken&#39;, &#39;cementfabrieken&#39;, &#39;delfstoffen&#39;, &#39;aardolie-&#39;, &#39;grondsteen&#39;, &#39;Steenkolen&#39;, &#39;steengroeve&#39;, &#39;mijnbouwindustrie&#39;, &#39;kalksteen&#39;]\n100%|██████████| 50/50 [00:00&lt;00:00, 85.12it/s]\n"
    }
   ],
   "source": [
    "li = []\n",
    "print(\"Searching synonyms\")\n",
    "for i, row in csv_articles.iterrows():\n",
    "    csv_file = pd.read_csv(row[\"csv_path\"])\n",
    "    li.append(csv_file)\n",
    "    if i % 5 == 0:\n",
    "        # Iterate 250.000 articles at the time\n",
    "        df_articles = pd.concat(li, axis=0)\n",
    "        df_articles.sort_values(by=[\"index\"], ascending=True)\n",
    "        df_articles.rename(\n",
    "            {\"filepath\": \"article_filepath\", \"index\": \"index_article\"},\n",
    "            axis=1,\n",
    "            inplace=True,\n",
    "        )\n",
    "        df_joined = df_articles.merge(df_metadata, how=\"left\", on=\"dir\")\n",
    "        #df_joined.dropna(subset=[\"text\"], inplace=True)\n",
    "        #df = df_joined[df_joined[\"text\"].str.contains(\"aardgas\", case=False, regex=False)]\n",
    "        #print(df_joined[df_joined[\"text\"].str.contains(\"aardgas\", case=False, regex=False)])\n",
    "        #df[\"count\"] = df[\"text\"].str.count(\"aardgas\")\n",
    "        #count = sum(1 for _ in re.finditer(r\"\\b%s\\b\" % re.escape(word), syn))\n",
    "\n",
    "        for keyword in KEYWORDS:\n",
    "            print(f\"Searching synonym {keyword}\")\n",
    "            selected_art = select_articles(\n",
    "                nlp=NLP, word=keyword, df=df_joined, n=NUM_SYNONYMS\n",
    "            )\n",
    "            today = datetime.now()\n",
    "            NAME = str(today.date()) + \"_\" + keyword + \".csv\"\n",
    "\n",
    "            selected_art.to_csv(\n",
    "                os.path.join(SAVE_PATH, \"selected_articles\", NAME),\n",
    "                sep=\",\",\n",
    "                quotechar='\"',\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        # Reset list of saved csv to zero\n",
    "        selected_art = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('histaware-RplM6c3o-py3.8')",
   "language": "python",
   "name": "python_defaultSpec_1602241163875"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}