{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from text_manager import TextManager\n",
    "from embedding import Word2VecEmbedding\n",
    "from lstm_model import LSTM_Model\n",
    "from cnn_model import CNN_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_DATA_DIR = '../../data/tmp'\n",
    "EMBEDDING_PATH = \"../../data/320/combined-320.txt\"\n",
    "OUTPUT_DIR = '../../data/output'\n",
    "MAX_NUM_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 12000\n",
    "\n",
    "data_fp = \"../../data/labeled/labeled_energy_1970_1990.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(data_fp):\n",
    "    \"\"\"Load dataset \n",
    "    \"\"\"\n",
    "\n",
    "    # read the data of the file location given as argument to this function\n",
    "    df = pd.read_csv(data_fp)\n",
    "\n",
    "    # make texts and labels\n",
    "    texts = df['text'].fillna('')\n",
    "    labels = df[\"labels\"]\n",
    "\n",
    "    return texts.values, labels.values\n",
    "\n",
    "\n",
    "def data_prep(data_fp):\n",
    "\n",
    "\n",
    "    # Dataset, labels and embedding layer are stored to disk in pickle file. \n",
    "    if not os.path.exists(TEMP_DATA_DIR):\n",
    "        os.makedirs(TEMP_DATA_DIR)\n",
    "        \n",
    "    pickle_fp = os.path.join(TEMP_DATA_DIR, 'hist_aware_pickle.pickle')\n",
    "\n",
    "    # load the dataset from disk\n",
    "    texts, lbls = load_dataset(data_fp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get the texts and their corresponding labels\n",
    "\n",
    "    textManager = TextManager(\n",
    "        max_num_words = MAX_NUM_WORDS,\n",
    "        max_sequence_length = MAX_SEQUENCE_LENGTH\n",
    "    )\n",
    "    \n",
    "    texts = textManager.clean_text(texts)\n",
    "    print('max length of all texts', len(max(texts, key=len)))\n",
    "    \n",
    "    data, labels, word_index = textManager.sequence_maker(texts, lbls)\n",
    "\n",
    "    if not os.path.exists(TEMP_DATA_DIR):\n",
    "        os.makedirs(TEMP_DATA_DIR)\n",
    "\n",
    "    embedding = Word2VecEmbedding(word_index, MAX_NUM_WORDS,\n",
    "                                  MAX_SEQUENCE_LENGTH)\n",
    "    embedding.load_word2vec_data(EMBEDDING_PATH)\n",
    "    embedding_layer = embedding.build_embedding()\n",
    "\n",
    "    with open(pickle_fp, 'wb') as f:\n",
    "        pickle.dump((data, labels, embedding_layer), f)\n",
    "\n",
    "def train_model(model, dropout=0):\n",
    "\n",
    "        \"\"\" Read dataset, labels and embedding layer from pickle file. \"\"\"\n",
    "        pickle_fp = os.path.join(TEMP_DATA_DIR, 'hist_aware_pickle.pickle')\n",
    "\n",
    "        with open(pickle_fp, 'rb') as f:\n",
    "            data, labels, embedding_layer = pickle.load(f)\n",
    "    \n",
    "\n",
    "        \"\"\" Split dataset to train and test \"\"\"\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data, labels,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=labels)\n",
    "            \n",
    "        print(\"x_train shape:\", x_train.shape, \", x_val shape:\", x_val.shape)\n",
    "        print(\"y_train shape:\", y_train.shape, \", y_val shape:\", y_val.shape)\n",
    "       \n",
    "        if model == 'lstm':\n",
    "            \"\"\" Make a lstm model \"\"\"\n",
    "            deep_model = LSTM_Model\n",
    "            args_model = {\n",
    "                'backwards': True,\n",
    "                'dropout': dropout,\n",
    "                'optimizer': 'rmsprop',\n",
    "                'max_sequence_length': MAX_SEQUENCE_LENGTH,\n",
    "                'embedding_layer': embedding_layer\n",
    "            }\n",
    "        elif model == 'cnn':\n",
    "            \"\"\" Make a cnn model \"\"\"\n",
    "            deep_model = CNN_Model\n",
    "            args_model = {\n",
    "                'dropout' : (0.5, 0.8),\n",
    "                'optimizer': 'rmsprop',\n",
    "                'max_sequence_length': MAX_SEQUENCE_LENGTH,\n",
    "                'embedding_layer': embedding_layer,\n",
    "                'kernel_size' : (3, 8),\n",
    "                'num_filters':  128\n",
    "            }\n",
    "            \n",
    "        \"\"\" Train model, calculate scores\"\"\"\n",
    "        model = deep_model(**args_model)\n",
    "        model.train(x_train, y_train, x_val, y_val)\n",
    "\n",
    "        \n",
    "\n",
    "        pred = model.predict(x_val)\n",
    "        \n",
    "         # store result in dataframe\n",
    "        df_y = pd.DataFrame({'sent_0': y_val[:,0],'sent_1': y_val[:,1],'sent_2': y_val[:,2]})\n",
    "        df_pred = pd.DataFrame({'sent_0': pred[:,0],'sent_1': pred[:,1],'sent_2': pred[:,2]})\n",
    "        \n",
    "        result_df = pd.concat([df_y.idxmax(axis=1),df_pred.idxmax(axis=1)], axis=1)\n",
    "        result_df.columns =['y_val','pred']\n",
    "        \n",
    "\n",
    "        \"\"\"Save the result to a file\"\"\"\n",
    "        \n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "                os.makedirs(OUTPUT_DIR)\n",
    "        export_path = os.path.join(OUTPUT_DIR, 'dropout{}.csv'.format(dropout))\n",
    "        result_df.to_csv(export_path,index=False)\n",
    "        df_pred.to_csv(os.path.join(OUTPUT_DIR,'preds_prob.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    # create model\n",
    "#     model = Keras Classifier(build_fn=create_model, verbose=0)\n",
    "    deep_model = CNN_Model\n",
    "    args_model = {\n",
    "            'optimizer': 'rmsprop',\n",
    "            'max_sequence_length': MAX_SEQUENCE_LENGTH,\n",
    "            'embedding_layer': embedding_layer\n",
    "    }\n",
    "\n",
    "    model = deep_model(**args_model)\n",
    "    \n",
    "    # define the grid search parameters\n",
    "    batch_size = [16,64,128]\n",
    "    epochs = [10, 50, 100]\n",
    "    dropout_prob = [0.0, 0.5, 0.8]\n",
    "    param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "    grid_result = grid.fit(X, Y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of all texts 11644\n",
      "Found 31517 unique tokens.\n",
      "Shape of data tensor: (6214, 12000)\n",
      "Shape of label tensor: (6214, 3)\n",
      "Indexing word vectors.\n",
      "Found 1442951 word vectors.\n",
      "Shape of embedding matrix:  (20000, 320)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropout = 0.0\n",
    "data_prep(data_fp)\n",
    "#train_lstm(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4163, 10000) , x_val shape: (2051, 10000)\n",
      "y_train shape: (4163, 3) , y_val shape: (2051, 3)\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10000)]           0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 10000, 320)        6400000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10)                13240     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 6,415,035\n",
      "Trainable params: 15,035\n",
      "Non-trainable params: 6,400,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "train_model('lstm',dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4163, 12000) , x_val shape: (2051, 12000)\n",
      "y_train shape: (4163, 3) , y_val shape: (2051, 3)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 12000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 12000, 320)   6400000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 12000, 320)   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 11998, 128)   123008      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 11993, 128)   327808      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5999, 128)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 5996, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 767872)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 767488)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1535360)      0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1535360)      0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           76768050    dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            153         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 83,619,019\n",
      "Trainable params: 77,219,019\n",
      "Non-trainable params: 6,400,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.0\n",
    "train_model('cnn',dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[403, 173,  41],\n",
       "       [119, 870,  60],\n",
       "       [ 68, 163, 154]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "export_path = os.path.join(OUTPUT_DIR, 'dropout{}.csv'.format(dropout))\n",
    "results = pd.read_csv(export_path)\n",
    "\n",
    "confusion_matrix(results['y_val'], results['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, accuracy_score\n",
    "\n",
    "def get_classification_report(y_test, preds):\n",
    "    cr = classification_report(y_test, preds , output_dict=True)\n",
    "    return pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent_0</th>\n",
       "      <td>0.683051</td>\n",
       "      <td>0.653160</td>\n",
       "      <td>0.667771</td>\n",
       "      <td>617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_1</th>\n",
       "      <td>0.721393</td>\n",
       "      <td>0.829361</td>\n",
       "      <td>0.771619</td>\n",
       "      <td>1049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_2</th>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.481250</td>\n",
       "      <td>385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.695758</td>\n",
       "      <td>0.695758</td>\n",
       "      <td>0.695758</td>\n",
       "      <td>0.695758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.669455</td>\n",
       "      <td>0.627507</td>\n",
       "      <td>0.640213</td>\n",
       "      <td>2051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.687808</td>\n",
       "      <td>0.695758</td>\n",
       "      <td>0.685872</td>\n",
       "      <td>2051.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "sent_0         0.683051  0.653160  0.667771   617.000000\n",
       "sent_1         0.721393  0.829361  0.771619  1049.000000\n",
       "sent_2         0.603922  0.400000  0.481250   385.000000\n",
       "accuracy       0.695758  0.695758  0.695758     0.695758\n",
       "macro avg      0.669455  0.627507  0.640213  2051.000000\n",
       "weighted avg   0.687808  0.695758  0.685872  2051.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_report(results['y_val'], results['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3179\n",
       "0    1868\n",
       "2    1167\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_fp)\n",
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sent_0</th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043188</td>\n",
       "      <td>0.293131</td>\n",
       "      <td>0.427964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.422813</td>\n",
       "      <td>0.107718</td>\n",
       "      <td>0.040513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.543416</td>\n",
       "      <td>0.068360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.198480</td>\n",
       "      <td>0.328709</td>\n",
       "      <td>0.460231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.499781</td>\n",
       "      <td>0.436155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2046</td>\n",
       "      <td>0.444020</td>\n",
       "      <td>0.391561</td>\n",
       "      <td>0.402332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2047</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.442935</td>\n",
       "      <td>0.373740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2048</td>\n",
       "      <td>0.426264</td>\n",
       "      <td>0.446767</td>\n",
       "      <td>0.399511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>2049</td>\n",
       "      <td>0.285063</td>\n",
       "      <td>0.464350</td>\n",
       "      <td>0.332162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>2050</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.406918</td>\n",
       "      <td>0.179857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    sent_0    sent_1    sent_2\n",
       "0              0  0.043188  0.293131  0.427964\n",
       "1              1  0.422813  0.107718  0.040513\n",
       "2              2  0.020714  0.543416  0.068360\n",
       "3              3  0.198480  0.328709  0.460231\n",
       "4              4  0.359744  0.499781  0.436155\n",
       "...          ...       ...       ...       ...\n",
       "2046        2046  0.444020  0.391561  0.402332\n",
       "2047        2047  0.300885  0.442935  0.373740\n",
       "2048        2048  0.426264  0.446767  0.399511\n",
       "2049        2049  0.285063  0.464350  0.332162\n",
       "2050        2050  0.072900  0.406918  0.179857\n",
       "\n",
       "[2051 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_path = os.path.join(OUTPUT_DIR, 'preds_prob.csv'.format(dropout))\n",
    "probs = pd.read_csv(export_path)\n",
    "\n",
    "probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array(['hello','world','!','Oooh gaaah booo gaah?'])\n",
    "max(a, key=len)\n",
    "len(max(a, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histaware-VpTDj7tf-py3.8",
   "language": "python",
   "name": "histaware-vptdj7tf-py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
