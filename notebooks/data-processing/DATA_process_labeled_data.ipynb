{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process selected labeled data and create DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import nltk.data\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import alpino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"~/dev/hist-aware/notebooks/data/labeled\"\n",
    "PRE_TRAINED_MODEL_NAME = 'wietsedv/bert-base-dutch-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols = ['sentiment', 'text', 'energy', 'article_filepath', 'article_name', 'count', 'date', 'dir', 'index_article', 'index_metadata', 'metadata_filepath',\n",
    "                    'newspaper_language', 'newspaper_publisher', 'newspaper_source', 'newspaper_title', 'newspaper_volume', \n",
    "             'newspaper_issuenumber', 'newspaper_city', 'text_clean', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    \"\"\"Function to clean df after concat\"\"\"\n",
    "    df.text.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    df.labels.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['labels'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gas_1970 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1970s_gas.csv\"))\n",
    "gas_1980 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1980s_gas.csv\"))\n",
    "gas_1990 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1990s_gas.csv\"))\n",
    "\n",
    "gas_1970 = gas_1970[list_cols]\n",
    "gas_1980 = gas_1980[list_cols]\n",
    "gas_1990 = gas_1990[list_cols]\n",
    "\n",
    "gas = gas_1970.append(gas_1980, ignore_index=True)\n",
    "gas = gas_1980.append(gas, ignore_index=True)\n",
    "gas = gas[gas.energy == \"Y\"]\n",
    "gas = gas[gas.sentiment != None]\n",
    "gas.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "gas = clean_df(gas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_1970 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1970s_oil.csv\"))\n",
    "gas_1980 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1980s_oil.csv\"))\n",
    "gas_1990 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1990s_oil.csv\"))\n",
    "\n",
    "\n",
    "oil_1970 = oil_1970[list_cols]\n",
    "oil_1980 = oil_1980[list_cols]\n",
    "oil_1990 = oil_1980[list_cols]\n",
    "\n",
    "oil = oil_1970.append(oil_1980, ignore_index=True)\n",
    "oil = oil.append(oil_1990, ignore_index=True)\n",
    "oil = oil[oil.energy == \"Y\"]\n",
    "oil = oil[oil.sentiment != None]\n",
    "oil.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "oil = clean_df(oil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_1970 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1970s_coal.csv\"))\n",
    "coal_1980 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1980s_coal.csv\"))\n",
    "coal_1990 = pd.read_csv(os.path.join(DATA_DIR, \"edo_1990s_coal.csv\"))\n",
    "coal_1990.drop([\"sentiment_gas\", \"sentiment_oil\"], axis=1, inplace=True)\n",
    "coal_1990.rename(columns = {\"sentiment\": \"accuracy_selection\", \"sentiment_coal\": \"sentiment\"}, inplace=True)\n",
    "\n",
    "coal_1970 = coal_1970[list_cols]\n",
    "coal_1980 = coal_1980[list_cols]\n",
    "coal_1990 = coal_1990[list_cols]\n",
    "\n",
    "coal = coal_1970.append(coal_1980, ignore_index=True)\n",
    "coal = coal.append(coal_1990, ignore_index=True)\n",
    "coal = coal[coal.energy == \"Y\"]\n",
    "coal = coal[coal.sentiment != None]\n",
    "coal.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "coal = clean_df(coal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4112, 20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([gas, oil, coal], ignore_index=True)\n",
    "df = clean_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_sentiment = {\"labels\": {\"VN\": 1, \"NG\": 2, \"NE\": 3, \"PO\": 4, \"VP\": 5}}\n",
    "oil = oil.replace(cleanup_sentiment)\n",
    "gas = gas.replace(cleanup_sentiment)\n",
    "coal = coal.replace(cleanup_sentiment)\n",
    "df = df.replace(cleanup_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(df.sentiment)\n",
    "#plt.xlabel('review sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce from 5 labels to 3 because of lack of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(rating):\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 0\n",
    "    elif rating == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['labels'] = df.labels.apply(to_sentiment)\n",
    "gas['labels'] = gas.labels.apply(to_sentiment)\n",
    "coal['labels'] = coal.labels.apply(to_sentiment)\n",
    "oil['labels'] = oil.labels.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(df.sentiment)\n",
    "#plt.xlabel('review sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split text and explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite(l, n):\n",
    "    \"\"\"Unite sentences previously split using nltk.tokenize.\"\"\"\n",
    "    count = []\n",
    "    chunks = []\n",
    "    sents = []\n",
    "    for s in l:\n",
    "        count.append(len(s.split()))\n",
    "    value = 0\n",
    "    prev_idx = 0\n",
    "    for i in range(0, len(count)):\n",
    "        if value == 0:\n",
    "            value = value + count[i]\n",
    "        elif (i+1 == len(count)):\n",
    "            chunks.append(l[prev_idx:i])\n",
    "            value = 0\n",
    "        elif value >= n:\n",
    "            chunks.append(l[prev_idx:i])\n",
    "            prev_idx = i\n",
    "            value = 0\n",
    "        else:\n",
    "             value = value + count[i]\n",
    "    for c in chunks:\n",
    "        sents.append(' '.join(c))\n",
    "    return(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(s, n):\n",
    "    \"\"\"Split sentences only using the number of words.\"\"\"\n",
    "    pieces = s.split()\n",
    "    return [\" \".join(pieces[i:i+n]) for i in range(0, len(pieces), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_SENTS = 250\n",
    "def apply_split_text(df):\n",
    "    df[\"text_split\"] = df[\"text\"].apply(sent_tokenize)\n",
    "    df[\"text_split\"] = df[\"text_split\"].apply(unite, n = LEN_SENTS)\n",
    "    df[\"text_split_max_len\"] = df[\"text\"].apply(splitter, n = 450)\n",
    "    df.text_split.replace([], np.nan, inplace=True)\n",
    "    df.dropna(subset=['text_split'], inplace=True)\n",
    "    # Cancel all text_split == 0\n",
    "    df.drop(df[df.text_split.map(len) == 0].index, inplace=True)\n",
    "    # Currently not splitting the cleaned sentences\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = apply_split_text(oil)\n",
    "gas = apply_split_text(gas)\n",
    "coal = apply_split_text(coal)\n",
    "df = apply_split_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explode the sentences that we created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('text_split')\n",
    "gas = gas.explode('text_split')\n",
    "coal = coal.explode('text_split')\n",
    "oil = oil.explode('text_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATA_DIR, \"labeled_energy_1970_1990.csv\"))\n",
    "gas.to_csv(os.path.join(DATA_DIR, \"labeled_gas_1970_1990.csv\"))\n",
    "coal.to_csv(os.path.join(DATA_DIR, \"labeled_coal_1970_1990.csv\"))\n",
    "oil.to_csv(os.path.join(DATA_DIR, \"labeled_oil_1970_1990.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histaware-fgpHC0Ao-py3.8",
   "language": "python",
   "name": "histaware-fgphc0ao-py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
