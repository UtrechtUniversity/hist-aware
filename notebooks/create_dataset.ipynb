{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hydraulic-governor",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decimal-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset as DT\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import wandb\n",
    "\n",
    "import nltk.data\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import alpino\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "republican-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banned-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'wietsedv/bert-base-dutch-cased'\n",
    "LEN_SENTS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ongoing-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-initial",
   "metadata": {},
   "source": [
    "## Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tested-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols = ['sentiment', 'text', 'energy', 'article_filepath', 'article_name', 'count', 'date', 'dir', 'index_article', 'index_metadata', 'metadata_filepath',\n",
    "                    'newspaper_language', 'newspaper_publisher', 'newspaper_source', 'newspaper_title', 'newspaper_volume', \n",
    "             'newspaper_issuenumber', 'newspaper_city', 'text_clean', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    \"\"\"Function to clean df after concat\"\"\"\n",
    "    df.text.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    df.labels.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['labels'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-defendant",
   "metadata": {},
   "source": [
    "### Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "obvious-performer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gas_1980 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1980s_gas.csv\")\n",
    "gas_1990 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1990s_gas_labeled.csv\")\n",
    "\n",
    "gas_1980 = gas_1980[list_cols]\n",
    "gas_1990 = gas_1990[list_cols]\n",
    "\n",
    "gas = gas_1980.append(gas_1990, ignore_index=True)\n",
    "gas = gas[gas.energy == \"Y\"]\n",
    "gas = gas[gas.sentiment != None]\n",
    "gas.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "gas = clean_df(gas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-greece",
   "metadata": {},
   "source": [
    "### Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sticky-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_1980 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1980s_oil.csv\")\n",
    "oil_1990 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1990s_olie_labeled.csv\")\n",
    "\n",
    "oil_1980 = oil_1980[list_cols]\n",
    "oil_1990 = oil_1980[list_cols]\n",
    "\n",
    "oil = oil_1980.append(oil_1990, ignore_index=True)\n",
    "oil = oil[oil.energy == \"Y\"]\n",
    "oil = oil[oil.sentiment != None]\n",
    "oil.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "oil = clean_df(oil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-wallet",
   "metadata": {},
   "source": [
    "### Coal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wanted-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_1980 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1980s_coal.csv\")\n",
    "coal_1990 = pd.read_csv(\"~/dev/hist-aware/notebooks/sentiment/edo_1990s_kool_labeled.csv\")\n",
    "coal_1990.drop([\"sentiment_gas\", \"sentiment_oil\"], axis=1, inplace=True)\n",
    "coal_1990.rename(columns = {\"sentiment\": \"accuracy_selection\", \"sentiment_coal\": \"sentiment\"}, inplace=True)\n",
    "\n",
    "coal_1980 = coal_1980[list_cols]\n",
    "coal_1990 = coal_1990[list_cols]\n",
    "\n",
    "coal = coal_1980.append(coal_1990, ignore_index=True)\n",
    "coal = coal[coal.energy == \"Y\"]\n",
    "coal = coal[coal.sentiment != None]\n",
    "coal.rename(columns = {\"sentiment\": \"labels\"}, inplace=True)\n",
    "coal = clean_df(coal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-beijing",
   "metadata": {},
   "source": [
    "### General df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "binding-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2773, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([gas, oil, coal], ignore_index=True)\n",
    "df = clean_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-cheat",
   "metadata": {},
   "source": [
    "## Fix labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abandoned-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_sentiment = {\"labels\": {\"VN\": 1, \"NG\": 2, \"NE\": 3, \"PO\": 4, \"VP\": 5}}\n",
    "oil = oil.replace(cleanup_sentiment)\n",
    "gas = gas.replace(cleanup_sentiment)\n",
    "coal = coal.replace(cleanup_sentiment)\n",
    "df = df.replace(cleanup_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "working-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(df.sentiment)\n",
    "#plt.xlabel('review sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-understanding",
   "metadata": {},
   "source": [
    "Reduce from 5 labels to 3 because of lack of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rough-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(rating):\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 0\n",
    "    elif rating == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['labels'] = df.labels.apply(to_sentiment)\n",
    "gas['labels'] = gas.labels.apply(to_sentiment)\n",
    "coal['labels'] = coal.labels.apply(to_sentiment)\n",
    "oil['labels'] = oil.labels.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recorded-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(df.sentiment)\n",
    "#plt.xlabel('review sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-scanner",
   "metadata": {},
   "source": [
    "### Split text and explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "italic-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite(l, n):\n",
    "    \"\"\"Unite sentences previously split using nltk.tokenize.\"\"\"\n",
    "    count = []\n",
    "    chunks = []\n",
    "    sents = []\n",
    "    for s in l:\n",
    "        count.append(len(s.split()))\n",
    "    value = 0\n",
    "    prev_idx = 0\n",
    "    for i in range(0, len(count)):\n",
    "        if value == 0:\n",
    "            value = value + count[i]\n",
    "        elif (i+1 == len(count)):\n",
    "            chunks.append(l[prev_idx:i])\n",
    "            value = 0\n",
    "        elif value >= n:\n",
    "            chunks.append(l[prev_idx:i])\n",
    "            prev_idx = i\n",
    "            value = 0\n",
    "        else:\n",
    "             value = value + count[i]\n",
    "    for c in chunks:\n",
    "        sents.append(' '.join(c))\n",
    "    return(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "permanent-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(s, n):\n",
    "    \"\"\"Split sentences only using the number of words.\"\"\"\n",
    "    pieces = s.split()\n",
    "    return [\" \".join(pieces[i:i+n]) for i in range(0, len(pieces), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tracked-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_split_text(df):\n",
    "    df[\"text_split\"] = df[\"text\"].apply(sent_tokenize)\n",
    "    df[\"text_split\"] = df[\"text_split\"].apply(unite, n = LEN_SENTS)\n",
    "    df.text_split.replace([], np.nan, inplace=True)\n",
    "    df.dropna(subset=['text_split'], inplace=True)\n",
    "    # Cancel all text_split == 0\n",
    "    df.drop(df[df.text_split.map(len) == 0].index, inplace=True)\n",
    "    # Currently not splitting the cleaned sentences\n",
    "    #df[\"text_clean_split\"] = df[\"text_clean\"].apply(splitter, n = LEN_SENTS)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "occupied-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = apply_split_text(oil)\n",
    "gas = apply_split_text(gas)\n",
    "coal = apply_split_text(coal)\n",
    "df = apply_split_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-nancy",
   "metadata": {},
   "source": [
    "Explode the sentences that we created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dressed-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('text_split')\n",
    "gas = gas.explode('text_split')\n",
    "coal = coal.explode('text_split')\n",
    "oil = oil.explode('text_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-lloyd",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "after-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DT.from_pandas(oil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "miniature-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b95c484b4ef428595968aa2728c0de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3232c46a272847c489a349a5e2f1c2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset = dataset.map(lambda par: tokenizer(\n",
    "    par['text_split'],\n",
    "    truncation=True,\n",
    "    padding=True),\n",
    "                      batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "binding-denver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29c4523001040e98ec265dc22011a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2686.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2b11e504b6455e83add0289df424d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=672.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset = dataset.map(lambda par: tokenizer.encode_plus(\n",
    "            par['text_split'],\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            max_length=350,\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "overhead-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AutoModel, AutoTokenizer, AutoConfig,\n",
    "                          Trainer, TrainingArguments)\n",
    "\n",
    "config = AutoConfig.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "bert_model = AutoModel.from_pretrained(\n",
    "    PRE_TRAINED_MODEL_NAME,\n",
    "    num_labels = 3)\n",
    "    #output_attentions = False, # Whether the model returns attentions weights.\n",
    "    #output_hidden_states = False, # Whether the model returns all hidden-states\n",
    "    #return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acceptable-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"hist-aware/notebooks/models\",\n",
    "    overwrite_output_dir = False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=4, # default is 8\n",
    "    per_device_eval_batch_size=4, # default is 8\n",
    "    logging_dir=\"hist-aware/notebooks/logging\",\n",
    "    eval_steps=500,\n",
    "    seed=RANDOM_SEED,\n",
    "    label_names=\"labels\", # check this\n",
    "    disable_tqdm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hydraulic-strain",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "type of [1, 0, 2358, 15730, 22307, 11, 6, 22693, 10537, 30, 23225, 29566, 11, 0, 15266, 11315, 13903, 12005, 8472, 13, 6, 3570, 11552, 13903, 11315, 15266, 22976, 10806, 25, 13041, 20722, 10537, 21953, 13644, 14742, 11, 0, 11281, 18883, 13, 7529, 11037, 13903, 22339, 10532, 5108, 13644, 11130, 17898, 17721, 28515, 21843, 14545, 16348, 22867, 11788, 13, 7778, 22795, 26709, 22384, 17795, 20722, 11130, 20722, 16760, 22331, 15963, 18312, 27102, 11, 13261, 8048, 11, 16804, 22300, 9645, 19732, 13, 3631, 13261, 16058, 20722, 3137, 17572, 11, 10516, 13903, 13261, 22339, 20722, 2511, 20407, 24660, 26751, 113, 8, 0, 13, 2003, 25128, 22777, 5114, 20183, 25108, 16804, 11130, 13136, 16804, 13261, 22795, 17179, 117, 7826, 25206, 27533, 117, 131, 117, 22834, 13644, 1503, 8394, 23984, 8227, 24770, 23967, 8421, 0, 12847, 128, 25099, 26457, 26148, 13, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] unknown: <class 'list'>. Should be one of a python, numpy, pytorch or tensorflow object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-5f6e962f0c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m# Defaut objective is the sum of all metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# when metrics are provided, so we have to maximize it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/histaware-NidRwJ64-py3.8/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/histaware-NidRwJ64-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/histaware-NidRwJ64-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/histaware-NidRwJ64-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/histaware-NidRwJ64-py3.8/lib/python3.8/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         batch = self.tokenizer.pad(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/histaware-NidRwJ64-py3.8/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2528\u001b[0m                 \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"np\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2531\u001b[0m                     \u001b[0;34mf\"type of {first_element} unknown: {type(first_element)}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m                     \u001b[0;34mf\"Should be one of a python, numpy, pytorch or tensorflow object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: type of [1, 0, 2358, 15730, 22307, 11, 6, 22693, 10537, 30, 23225, 29566, 11, 0, 15266, 11315, 13903, 12005, 8472, 13, 6, 3570, 11552, 13903, 11315, 15266, 22976, 10806, 25, 13041, 20722, 10537, 21953, 13644, 14742, 11, 0, 11281, 18883, 13, 7529, 11037, 13903, 22339, 10532, 5108, 13644, 11130, 17898, 17721, 28515, 21843, 14545, 16348, 22867, 11788, 13, 7778, 22795, 26709, 22384, 17795, 20722, 11130, 20722, 16760, 22331, 15963, 18312, 27102, 11, 13261, 8048, 11, 16804, 22300, 9645, 19732, 13, 3631, 13261, 16058, 20722, 3137, 17572, 11, 10516, 13903, 13261, 22339, 20722, 2511, 20407, 24660, 26751, 113, 8, 0, 13, 2003, 25128, 22777, 5114, 20183, 25108, 16804, 11130, 13136, 16804, 13261, 22795, 17179, 117, 7826, 25206, 27533, 117, 131, 117, 22834, 13644, 1503, 8394, 23984, 8227, 24770, 23967, 8421, 0, 12847, 128, 25099, 26457, 26148, 13, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] unknown: <class 'list'>. Should be one of a python, numpy, pytorch or tensorflow object."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def model_init():\n",
    "    return bert_model\n",
    "\n",
    "def compute_metrics_old(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Evaluate during training and a bit more often\n",
    "# than the default to be able to prune bad trials early.\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    model_init=model_init,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# Defaut objective is the sum of all metrics\n",
    "# when metrics are provided, so we have to maximize it.\n",
    "#trainer.hyperparameter_search(\n",
    "#    direction=\"maximize\", \n",
    "#    backend=\"ray\", \n",
    "#   n_trials=100, # deafult 100\n",
    "#    # n_jobs=2  # number of parallel jobs, if multiple GPUs\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-marine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-patent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histaware-NidRwJ64-py3.8",
   "language": "python",
   "name": "histaware-nidrwj64-py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
